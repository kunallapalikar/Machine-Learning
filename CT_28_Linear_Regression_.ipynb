{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CT-28 Linear Regression .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJM8ymxD96uR"
      },
      "source": [
        "class MyLinearRegression:\n",
        "    def __init__(self, weight=9.84957055, bias=3.4867, learning_rate=0.01,\n",
        "                 iterations=1000):\n",
        "        self.weight = weight\n",
        "        self.bias = bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.cost_trend = []\n",
        "        self.cost = 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        predicted_set = []\n",
        "        for i in range(len(x)):\n",
        "            predicted_value = self.weight * x[i] + self.bias\n",
        "            predicted_set.append(predicted_value)\n",
        "        return predicted_set\n",
        "\n",
        "    def cost_function(self, x, y):\n",
        "        count = len(x)\n",
        "        total_error = 0.0\n",
        "        for i in range(count):\n",
        "            total_error += (y[i] - (self.weight * x[i] +\n",
        "                            self.bias)) ** 2\n",
        "        return float(total_error) / (2 * count)\n",
        "\n",
        "    def update_weights(self, x, y):\n",
        "        weight_deriv = 0\n",
        "        bias_deriv = 0\n",
        "        count = len(x)\n",
        "\n",
        "        for i in range(count):\n",
        "            # Calculate partial derivatives\n",
        "            # -2x(y - (mx + b))\n",
        "            weight_deriv += -2 * x[i] * (y[i] -(self.weight * x[i] + self.bias))\n",
        "\n",
        "            # -2(y - (mx + b))\n",
        "            bias_deriv += -2 * (y[i] - (self.weight * x[i] +\n",
        "                                self.bias))\n",
        "\n",
        "        # We subtract because the derivatives point in direction of steepest\n",
        "        # ascent\n",
        "        self.weight -= (weight_deriv / count) * self.learning_rate\n",
        "        self.bias -= (bias_deriv / count) * self.learning_rate\n",
        "\n",
        "    def train(self, x, y):\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights(x, y)\n",
        "            # Calculating cost\n",
        "            self.cost = self.cost_function(x, y)\n",
        "            self.cost_trend.append(self.cost)\n",
        "           # if i % 10000 == 0:\n",
        "            print(\"Iteration: {}\\t Weight: {}\\t Bias: {}\\t Cost: {}\".format(i, self.weight, self.bias, self.cost))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "10qv2JGFoqfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGMUmPfj96ua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "94d5055a-c190-4a4c-864a-d834dad9abeb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# intialise data of lists. \n",
        "data = {'Hours':[1,2,3,4,5,6,7,8,9,10], \n",
        "        'Scores':[2,4,6,8,10,12,14,16,18,20]} \n",
        "  \n",
        "# Create DataFrame \n",
        "studentscores = pd.DataFrame(data) \n",
        "  \n",
        "# Print the output. \n",
        "studentscores "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9db8a60a-4861-463d-abb2-75fa8db5ee3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9db8a60a-4861-463d-abb2-75fa8db5ee3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9db8a60a-4861-463d-abb2-75fa8db5ee3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9db8a60a-4861-463d-abb2-75fa8db5ee3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Hours  Scores\n",
              "0      1       2\n",
              "1      2       4\n",
              "2      3       6\n",
              "3      4       8\n",
              "4      5      10\n",
              "5      6      12\n",
              "6      7      14\n",
              "7      8      16\n",
              "8      9      18\n",
              "9     10      20"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avh401TI11sH",
        "outputId": "c7c2ddee-bdb9-449f-f05d-6cc5e239291e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x=[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8] \n",
        "y=[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]\n",
        "plt.scatter(x,y,s=30)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LSp2jKt96uj",
        "outputId": "8c20d230-ec7a-4174-fa4e-6de4a53e9094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#from my_linear_regression import MyLinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "X = studentscores.iloc[:, : -1].values\n",
        "y = studentscores.iloc[:, -1].values\n",
        "X,y"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1],\n",
              "        [ 2],\n",
              "        [ 3],\n",
              "        [ 4],\n",
              "        [ 5],\n",
              "        [ 6],\n",
              "        [ 7],\n",
              "        [ 8],\n",
              "        [ 9],\n",
              "        [10]]), array([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvfKE_WT96un",
        "outputId": "9fe65051-dea6-43b3-94f6-f81fea120a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/10, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor = MyLinearRegression()\n",
        "regressor.train(X_train, y_train)\n",
        "print('Weight: ' + str(regressor.weight) + ' Bias: ' + str(regressor.bias))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0\t Weight: [2.88791071]\t Bias: [2.50990451]\t Cost: 32.49449467291663\n",
            "Iteration: 1\t Weight: [1.85597857]\t Bias: [2.35710341]\t Cost: 1.2498473094000309\n",
            "Iteration: 2\t Weight: [1.70394008]\t Bias: [2.32660382]\t Cost: 0.5576695801177172\n",
            "Iteration: 3\t Weight: [1.68246259]\t Bias: [2.31428311]\t Cost: 0.5382559452148103\n",
            "Iteration: 4\t Weight: [1.68035447]\t Bias: [2.30469066]\t Cost: 0.5336886602854467\n",
            "Iteration: 5\t Weight: [1.68111626]\t Bias: [2.29553366]\t Cost: 0.5294808586502158\n",
            "Iteration: 6\t Weight: [1.68229967]\t Bias: [2.28647178]\t Cost: 0.5253132993561694\n",
            "Iteration: 7\t Weight: [1.68354143]\t Bias: [2.27745438]\t Cost: 0.5211786986404898\n",
            "Iteration: 8\t Weight: [1.68478764]\t Bias: [2.26847384]\t Cost: 0.5170766436891495\n",
            "Iteration: 9\t Weight: [1.68603032]\t Bias: [2.2595289]\t Cost: 0.5130068749655159\n",
            "Iteration: 10\t Weight: [1.68726831]\t Bias: [2.25061926]\t Cost: 0.508969138279155\n",
            "Iteration: 11\t Weight: [1.68850145]\t Bias: [2.24174476]\t Cost: 0.5049631815130293\n",
            "Iteration: 12\t Weight: [1.68972973]\t Bias: [2.23290525]\t Cost: 0.5009887545360516\n",
            "Iteration: 13\t Weight: [1.69095317]\t Bias: [2.2241006]\t Cost: 0.49704560918588137\n",
            "Iteration: 14\t Weight: [1.69217179]\t Bias: [2.21533067]\t Cost: 0.4931334992533956\n",
            "Iteration: 15\t Weight: [1.69338559]\t Bias: [2.20659531]\t Cost: 0.4892521804673181\n",
            "Iteration: 16\t Weight: [1.69459462]\t Bias: [2.1978944]\t Cost: 0.4854014104789631\n",
            "Iteration: 17\t Weight: [1.69579887]\t Bias: [2.18922781]\t Cost: 0.48158094884710706\n",
            "Iteration: 18\t Weight: [1.69699838]\t Bias: [2.18059538]\t Cost: 0.4777905570229717\n",
            "Iteration: 19\t Weight: [1.69819316]\t Bias: [2.17199699]\t Cost: 0.4740299983353313\n",
            "Iteration: 20\t Weight: [1.69938322]\t Bias: [2.16343251]\t Cost: 0.47029903797573513\n",
            "Iteration: 21\t Weight: [1.7005686]\t Bias: [2.1549018]\t Cost: 0.4665974429838451\n",
            "Iteration: 22\t Weight: [1.70174929]\t Bias: [2.14640473]\t Cost: 0.4629249822328903\n",
            "Iteration: 23\t Weight: [1.70292534]\t Bias: [2.13794116]\t Cost: 0.4592814264152356\n",
            "Iteration: 24\t Weight: [1.70409674]\t Bias: [2.12951096]\t Cost: 0.45566654802806256\n",
            "Iteration: 25\t Weight: [1.70526353]\t Bias: [2.12111401]\t Cost: 0.45208012135916636\n",
            "Iteration: 26\t Weight: [1.70642572]\t Bias: [2.11275016]\t Cost: 0.4485219224728604\n",
            "Iteration: 27\t Weight: [1.70758332]\t Bias: [2.1044193]\t Cost: 0.4449917291959948\n",
            "Iteration: 28\t Weight: [1.70873636]\t Bias: [2.09612129]\t Cost: 0.4414893211040834\n",
            "Iteration: 29\t Weight: [1.70988485]\t Bias: [2.08785599]\t Cost: 0.4380144795075416\n",
            "Iteration: 30\t Weight: [1.71102882]\t Bias: [2.07962329]\t Cost: 0.43456698743802974\n",
            "Iteration: 31\t Weight: [1.71216827]\t Bias: [2.07142305]\t Cost: 0.4311466296349073\n",
            "Iteration: 32\t Weight: [1.71330323]\t Bias: [2.06325514]\t Cost: 0.4277531925317908\n",
            "Iteration: 33\t Weight: [1.71443371]\t Bias: [2.05511944]\t Cost: 0.42438646424322013\n",
            "Iteration: 34\t Weight: [1.71555974]\t Bias: [2.04701583]\t Cost: 0.4210462345514266\n",
            "Iteration: 35\t Weight: [1.71668133]\t Bias: [2.03894416]\t Cost: 0.4177322948932084\n",
            "Iteration: 36\t Weight: [1.71779849]\t Bias: [2.03090432]\t Cost: 0.4144444383469075\n",
            "Iteration: 37\t Weight: [1.71891125]\t Bias: [2.02289619]\t Cost: 0.4111824596194905\n",
            "Iteration: 38\t Weight: [1.72001962]\t Bias: [2.01491963]\t Cost: 0.40794615503372833\n",
            "Iteration: 39\t Weight: [1.72112363]\t Bias: [2.00697453]\t Cost: 0.40473532251547933\n",
            "Iteration: 40\t Weight: [1.72222327]\t Bias: [1.99906075]\t Cost: 0.4015497615810737\n",
            "Iteration: 41\t Weight: [1.72331858]\t Bias: [1.99117818]\t Cost: 0.398389273324791\n",
            "Iteration: 42\t Weight: [1.72440958]\t Bias: [1.98332669]\t Cost: 0.3952536604064469\n",
            "Iteration: 43\t Weight: [1.72549627]\t Bias: [1.97550616]\t Cost: 0.3921427270390645\n",
            "Iteration: 44\t Weight: [1.72657867]\t Bias: [1.96771647]\t Cost: 0.3890562789766537\n",
            "Iteration: 45\t Weight: [1.72765681]\t Bias: [1.95995749]\t Cost: 0.38599412350208184\n",
            "Iteration: 46\t Weight: [1.7287307]\t Bias: [1.95222911]\t Cost: 0.3829560694150394\n",
            "Iteration: 47\t Weight: [1.72980035]\t Bias: [1.94453121]\t Cost: 0.379941927020103\n",
            "Iteration: 48\t Weight: [1.73086579]\t Bias: [1.93686365]\t Cost: 0.3769515081148891\n",
            "Iteration: 49\t Weight: [1.73192702]\t Bias: [1.92922633]\t Cost: 0.37398462597830373\n",
            "Iteration: 50\t Weight: [1.73298407]\t Bias: [1.92161913]\t Cost: 0.3710410953588842\n",
            "Iteration: 51\t Weight: [1.73403695]\t Bias: [1.91404192]\t Cost: 0.36812073246323135\n",
            "Iteration: 52\t Weight: [1.73508568]\t Bias: [1.90649459]\t Cost: 0.3652233549445317\n",
            "Iteration: 53\t Weight: [1.73613027]\t Bias: [1.89897702]\t Cost: 0.3623487818911769\n",
            "Iteration: 54\t Weight: [1.73717074]\t Bias: [1.89148909]\t Cost: 0.3594968338154612\n",
            "Iteration: 55\t Weight: [1.73820712]\t Bias: [1.88403069]\t Cost: 0.3566673326423795\n",
            "Iteration: 56\t Weight: [1.7392394]\t Bias: [1.8766017]\t Cost: 0.353860101698505\n",
            "Iteration: 57\t Weight: [1.74026762]\t Bias: [1.869202]\t Cost: 0.35107496570096053\n",
            "Iteration: 58\t Weight: [1.74129178]\t Bias: [1.86183148]\t Cost: 0.34831175074647125\n",
            "Iteration: 59\t Weight: [1.7423119]\t Bias: [1.85449002]\t Cost: 0.3455702843005074\n",
            "Iteration: 60\t Weight: [1.743328]\t Bias: [1.84717752]\t Cost: 0.342850395186512\n",
            "Iteration: 61\t Weight: [1.74434009]\t Bias: [1.83989384]\t Cost: 0.3401519135752114\n",
            "Iteration: 62\t Weight: [1.74534819]\t Bias: [1.83263889]\t Cost: 0.3374746709740117\n",
            "Iteration: 63\t Weight: [1.74635232]\t Bias: [1.82541254]\t Cost: 0.33481850021647885\n",
            "Iteration: 64\t Weight: [1.74735249]\t Bias: [1.81821469]\t Cost: 0.3321832354518984\n",
            "Iteration: 65\t Weight: [1.74834871]\t Bias: [1.81104522]\t Cost: 0.3295687121349233\n",
            "Iteration: 66\t Weight: [1.74934101]\t Bias: [1.80390402]\t Cost: 0.32697476701529704\n",
            "Iteration: 67\t Weight: [1.75032939]\t Bias: [1.79679098]\t Cost: 0.3244012381276605\n",
            "Iteration: 68\t Weight: [1.75131388]\t Bias: [1.78970598]\t Cost: 0.3218479647814409\n",
            "Iteration: 69\t Weight: [1.75229448]\t Bias: [1.78264893]\t Cost: 0.3193147875508158\n",
            "Iteration: 70\t Weight: [1.75327122]\t Bias: [1.7756197]\t Cost: 0.31680154826476087\n",
            "Iteration: 71\t Weight: [1.7542441]\t Bias: [1.76861819]\t Cost: 0.31430808999717175\n",
            "Iteration: 72\t Weight: [1.75521315]\t Bias: [1.76164428]\t Cost: 0.31183425705706697\n",
            "Iteration: 73\t Weight: [1.75617838]\t Bias: [1.75469788]\t Cost: 0.3093798949788654\n",
            "Iteration: 74\t Weight: [1.7571398]\t Bias: [1.74777886]\t Cost: 0.30694485051274406\n",
            "Iteration: 75\t Weight: [1.75809743]\t Bias: [1.74088713]\t Cost: 0.3045289716150647\n",
            "Iteration: 76\t Weight: [1.75905129]\t Bias: [1.73402257]\t Cost: 0.30213210743888563\n",
            "Iteration: 77\t Weight: [1.76000138]\t Bias: [1.72718508]\t Cost: 0.29975410832453764\n",
            "Iteration: 78\t Weight: [1.76094773]\t Bias: [1.72037456]\t Cost: 0.2973948257902835\n",
            "Iteration: 79\t Weight: [1.76189034]\t Bias: [1.71359088]\t Cost: 0.2950541125230452\n",
            "Iteration: 80\t Weight: [1.76282924]\t Bias: [1.70683396]\t Cost: 0.2927318223692047\n",
            "Iteration: 81\t Weight: [1.76376444]\t Bias: [1.70010368]\t Cost: 0.29042781032547876\n",
            "Iteration: 82\t Weight: [1.76469595]\t Bias: [1.69339994]\t Cost: 0.2881419325298673\n",
            "Iteration: 83\t Weight: [1.76562379]\t Bias: [1.68672263]\t Cost: 0.28587404625266627\n",
            "Iteration: 84\t Weight: [1.76654796]\t Bias: [1.68007165]\t Cost: 0.28362400988755954\n",
            "Iteration: 85\t Weight: [1.7674685]\t Bias: [1.67344689]\t Cost: 0.28139168294277483\n",
            "Iteration: 86\t Weight: [1.7683854]\t Bias: [1.66684826]\t Cost: 0.2791769260323131\n",
            "Iteration: 87\t Weight: [1.76929869]\t Bias: [1.66027565]\t Cost: 0.27697960086724244\n",
            "Iteration: 88\t Weight: [1.77020838]\t Bias: [1.65372896]\t Cost: 0.2747995702470678\n",
            "Iteration: 89\t Weight: [1.77111448]\t Bias: [1.64720808]\t Cost: 0.27263669805115964\n",
            "Iteration: 90\t Weight: [1.772017]\t Bias: [1.64071291]\t Cost: 0.2704908492302577\n",
            "Iteration: 91\t Weight: [1.77291597]\t Bias: [1.63424335]\t Cost: 0.2683618897980373\n",
            "Iteration: 92\t Weight: [1.77381139]\t Bias: [1.62779931]\t Cost: 0.26624968682274236\n",
            "Iteration: 93\t Weight: [1.77470329]\t Bias: [1.62138067]\t Cost: 0.26415410841888853\n",
            "Iteration: 94\t Weight: [1.77559166]\t Bias: [1.61498734]\t Cost: 0.2620750237390237\n",
            "Iteration: 95\t Weight: [1.77647654]\t Bias: [1.60861923]\t Cost: 0.2600123029655616\n",
            "Iteration: 96\t Weight: [1.77735792]\t Bias: [1.60227622]\t Cost: 0.2579658173026738\n",
            "Iteration: 97\t Weight: [1.77823583]\t Bias: [1.59595823]\t Cost: 0.25593543896825016\n",
            "Iteration: 98\t Weight: [1.77911027]\t Bias: [1.58966514]\t Cost: 0.2539210411859163\n",
            "Iteration: 99\t Weight: [1.77998127]\t Bias: [1.58339688]\t Cost: 0.2519224981771218\n",
            "Iteration: 100\t Weight: [1.78084884]\t Bias: [1.57715332]\t Cost: 0.2499396851532835\n",
            "Iteration: 101\t Weight: [1.78171298]\t Bias: [1.57093439]\t Cost: 0.2479724783079963\n",
            "Iteration: 102\t Weight: [1.78257372]\t Bias: [1.56473998]\t Cost: 0.24602075480930022\n",
            "Iteration: 103\t Weight: [1.78343106]\t Bias: [1.55857]\t Cost: 0.2440843927920126\n",
            "Iteration: 104\t Weight: [1.78428502]\t Bias: [1.55242434]\t Cost: 0.24216327135011836\n",
            "Iteration: 105\t Weight: [1.78513561]\t Bias: [1.54630292]\t Cost: 0.24025727052922083\n",
            "Iteration: 106\t Weight: [1.78598285]\t Bias: [1.54020564]\t Cost: 0.23836627131905028\n",
            "Iteration: 107\t Weight: [1.78682675]\t Bias: [1.53413239]\t Cost: 0.23649015564603534\n",
            "Iteration: 108\t Weight: [1.78766732]\t Bias: [1.5280831]\t Cost: 0.23462880636592937\n",
            "Iteration: 109\t Weight: [1.78850458]\t Bias: [1.52205766]\t Cost: 0.2327821072564958\n",
            "Iteration: 110\t Weight: [1.78933853]\t Bias: [1.51605597]\t Cost: 0.23094994301025182\n",
            "Iteration: 111\t Weight: [1.7901692]\t Bias: [1.51007796]\t Cost: 0.22913219922726727\n",
            "Iteration: 112\t Weight: [1.79099659]\t Bias: [1.50412351]\t Cost: 0.2273287624080236\n",
            "Iteration: 113\t Weight: [1.79182072]\t Bias: [1.49819255]\t Cost: 0.2255395199463248\n",
            "Iteration: 114\t Weight: [1.7926416]\t Bias: [1.49228497]\t Cost: 0.22376436012226947\n",
            "Iteration: 115\t Weight: [1.79345924]\t Bias: [1.48640068]\t Cost: 0.22200317209527035\n",
            "Iteration: 116\t Weight: [1.79427366]\t Bias: [1.4805396]\t Cost: 0.22025584589713784\n",
            "Iteration: 117\t Weight: [1.79508487]\t Bias: [1.47470163]\t Cost: 0.21852227242521124\n",
            "Iteration: 118\t Weight: [1.79589288]\t Bias: [1.46888668]\t Cost: 0.2168023434355473\n",
            "Iteration: 119\t Weight: [1.7966977]\t Bias: [1.46309466]\t Cost: 0.2150959515361608\n",
            "Iteration: 120\t Weight: [1.79749935]\t Bias: [1.45732547]\t Cost: 0.2134029901803201\n",
            "Iteration: 121\t Weight: [1.79829784]\t Bias: [1.45157904]\t Cost: 0.21172335365989287\n",
            "Iteration: 122\t Weight: [1.79909318]\t Bias: [1.44585526]\t Cost: 0.21005693709874704\n",
            "Iteration: 123\t Weight: [1.79988538]\t Bias: [1.44015406]\t Cost: 0.20840363644620252\n",
            "Iteration: 124\t Weight: [1.80067446]\t Bias: [1.43447533]\t Cost: 0.2067633484705321\n",
            "Iteration: 125\t Weight: [1.80146043]\t Bias: [1.428819]\t Cost: 0.2051359707525189\n",
            "Iteration: 126\t Weight: [1.8022433]\t Bias: [1.42318497]\t Cost: 0.20352140167905802\n",
            "Iteration: 127\t Weight: [1.80302308]\t Bias: [1.41757316]\t Cost: 0.20191954043681468\n",
            "Iteration: 128\t Weight: [1.80379979]\t Bias: [1.41198347]\t Cost: 0.20033028700592814\n",
            "Iteration: 129\t Weight: [1.80457343]\t Bias: [1.40641583]\t Cost: 0.19875354215376614\n",
            "Iteration: 130\t Weight: [1.80534402]\t Bias: [1.40087014]\t Cost: 0.1971892074287294\n",
            "Iteration: 131\t Weight: [1.80611158]\t Bias: [1.39534631]\t Cost: 0.19563718515410475\n",
            "Iteration: 132\t Weight: [1.80687611]\t Bias: [1.38984427]\t Cost: 0.19409737842196512\n",
            "Iteration: 133\t Weight: [1.80763762]\t Bias: [1.38436392]\t Cost: 0.19256969108711924\n",
            "Iteration: 134\t Weight: [1.80839613]\t Bias: [1.37890519]\t Cost: 0.19105402776110875\n",
            "Iteration: 135\t Weight: [1.80915165]\t Bias: [1.37346797]\t Cost: 0.18955029380625132\n",
            "Iteration: 136\t Weight: [1.80990419]\t Bias: [1.3680522]\t Cost: 0.18805839532973195\n",
            "Iteration: 137\t Weight: [1.81065377]\t Bias: [1.36265778]\t Cost: 0.18657823917774075\n",
            "Iteration: 138\t Weight: [1.81140039]\t Bias: [1.35728464]\t Cost: 0.18510973292965507\n",
            "Iteration: 139\t Weight: [1.81214406]\t Bias: [1.35193268]\t Cost: 0.18365278489227085\n",
            "Iteration: 140\t Weight: [1.8128848]\t Bias: [1.34660182]\t Cost: 0.18220730409407518\n",
            "Iteration: 141\t Weight: [1.81362262]\t Bias: [1.34129199]\t Cost: 0.18077320027956745\n",
            "Iteration: 142\t Weight: [1.81435754]\t Bias: [1.33600309]\t Cost: 0.17935038390362293\n",
            "Iteration: 143\t Weight: [1.81508955]\t Bias: [1.33073504]\t Cost: 0.1779387661259029\n",
            "Iteration: 144\t Weight: [1.81581868]\t Bias: [1.32548777]\t Cost: 0.17653825880530585\n",
            "Iteration: 145\t Weight: [1.81654493]\t Bias: [1.32026119]\t Cost: 0.17514877449446528\n",
            "Iteration: 146\t Weight: [1.81726832]\t Bias: [1.31505522]\t Cost: 0.1737702264342889\n",
            "Iteration: 147\t Weight: [1.81798885]\t Bias: [1.30986978]\t Cost: 0.17240252854854077\n",
            "Iteration: 148\t Weight: [1.81870655]\t Bias: [1.30470478]\t Cost: 0.17104559543846867\n",
            "Iteration: 149\t Weight: [1.81942141]\t Bias: [1.29956015]\t Cost: 0.16969934237746934\n",
            "Iteration: 150\t Weight: [1.82013346]\t Bias: [1.29443581]\t Cost: 0.16836368530580004\n",
            "Iteration: 151\t Weight: [1.8208427]\t Bias: [1.28933167]\t Cost: 0.16703854082532973\n",
            "Iteration: 152\t Weight: [1.82154914]\t Bias: [1.28424766]\t Cost: 0.16572382619433032\n",
            "Iteration: 153\t Weight: [1.8222528]\t Bias: [1.27918369]\t Cost: 0.16441945932231172\n",
            "Iteration: 154\t Weight: [1.82295368]\t Bias: [1.2741397]\t Cost: 0.16312535876489576\n",
            "Iteration: 155\t Weight: [1.8236518]\t Bias: [1.26911559]\t Cost: 0.1618414437187298\n",
            "Iteration: 156\t Weight: [1.82434716]\t Bias: [1.26411129]\t Cost: 0.16056763401644325\n",
            "Iteration: 157\t Weight: [1.82503978]\t Bias: [1.25912673]\t Cost: 0.15930385012164083\n",
            "Iteration: 158\t Weight: [1.82572968]\t Bias: [1.25416182]\t Cost: 0.15805001312393593\n",
            "Iteration: 159\t Weight: [1.82641685]\t Bias: [1.24921648]\t Cost: 0.1568060447340242\n",
            "Iteration: 160\t Weight: [1.82710131]\t Bias: [1.24429065]\t Cost: 0.15557186727879502\n",
            "Iteration: 161\t Weight: [1.82778307]\t Bias: [1.23938424]\t Cost: 0.1543474036964822\n",
            "Iteration: 162\t Weight: [1.82846215]\t Bias: [1.23449718]\t Cost: 0.1531325775318504\n",
            "Iteration: 163\t Weight: [1.82913855]\t Bias: [1.22962939]\t Cost: 0.15192731293142325\n",
            "Iteration: 164\t Weight: [1.82981228]\t Bias: [1.22478079]\t Cost: 0.15073153463874617\n",
            "Iteration: 165\t Weight: [1.83048335]\t Bias: [1.21995131]\t Cost: 0.14954516798968792\n",
            "Iteration: 166\t Weight: [1.83115178]\t Bias: [1.21514088]\t Cost: 0.14836813890777747\n",
            "Iteration: 167\t Weight: [1.83181757]\t Bias: [1.21034941]\t Cost: 0.14720037389957968\n",
            "Iteration: 168\t Weight: [1.83248073]\t Bias: [1.20557684]\t Cost: 0.1460418000501067\n",
            "Iteration: 169\t Weight: [1.83314129]\t Bias: [1.20082308]\t Cost: 0.1448923450182641\n",
            "Iteration: 170\t Weight: [1.83379923]\t Bias: [1.19608807]\t Cost: 0.1437519370323339\n",
            "Iteration: 171\t Weight: [1.83445459]\t Bias: [1.19137173]\t Cost: 0.14262050488549444\n",
            "Iteration: 172\t Weight: [1.83510735]\t Bias: [1.18667399]\t Cost: 0.1414979779313735\n",
            "Iteration: 173\t Weight: [1.83575755]\t Bias: [1.18199477]\t Cost: 0.14038428607963643\n",
            "Iteration: 174\t Weight: [1.83640518]\t Bias: [1.177334]\t Cost: 0.139279359791611\n",
            "Iteration: 175\t Weight: [1.83705026]\t Bias: [1.17269161]\t Cost: 0.1381831300759448\n",
            "Iteration: 176\t Weight: [1.83769279]\t Bias: [1.16806753]\t Cost: 0.13709552848429737\n",
            "Iteration: 177\t Weight: [1.83833279]\t Bias: [1.16346168]\t Cost: 0.13601648710706554\n",
            "Iteration: 178\t Weight: [1.83897026]\t Bias: [1.15887399]\t Cost: 0.13494593856914602\n",
            "Iteration: 179\t Weight: [1.83960523]\t Bias: [1.15430439]\t Cost: 0.13388381602572452\n",
            "Iteration: 180\t Weight: [1.84023769]\t Bias: [1.14975281]\t Cost: 0.13283005315810525\n",
            "Iteration: 181\t Weight: [1.84086765]\t Bias: [1.14521918]\t Cost: 0.13178458416956804\n",
            "Iteration: 182\t Weight: [1.84149513]\t Bias: [1.14070342]\t Cost: 0.13074734378126124\n",
            "Iteration: 183\t Weight: [1.84212014]\t Bias: [1.13620547]\t Cost: 0.12971826722812416\n",
            "Iteration: 184\t Weight: [1.84274268]\t Bias: [1.13172526]\t Cost: 0.1286972902548459\n",
            "Iteration: 185\t Weight: [1.84336277]\t Bias: [1.12726271]\t Cost: 0.12768434911184962\n",
            "Iteration: 186\t Weight: [1.84398041]\t Bias: [1.12281776]\t Cost: 0.12667938055131542\n",
            "Iteration: 187\t Weight: [1.84459562]\t Bias: [1.11839033]\t Cost: 0.12568232182322875\n",
            "Iteration: 188\t Weight: [1.8452084]\t Bias: [1.11398037]\t Cost: 0.12469311067146349\n",
            "Iteration: 189\t Weight: [1.84581876]\t Bias: [1.10958779]\t Cost: 0.12371168532989513\n",
            "Iteration: 190\t Weight: [1.84642672]\t Bias: [1.10521253]\t Cost: 0.12273798451854237\n",
            "Iteration: 191\t Weight: [1.84703228]\t Bias: [1.10085453]\t Cost: 0.12177194743974244\n",
            "Iteration: 192\t Weight: [1.84763545]\t Bias: [1.09651371]\t Cost: 0.12081351377435416\n",
            "Iteration: 193\t Weight: [1.84823625]\t Bias: [1.09219]\t Cost: 0.11986262367799234\n",
            "Iteration: 194\t Weight: [1.84883467]\t Bias: [1.08788335]\t Cost: 0.11891921777728925\n",
            "Iteration: 195\t Weight: [1.84943074]\t Bias: [1.08359367]\t Cost: 0.11798323716619012\n",
            "Iteration: 196\t Weight: [1.85002445]\t Bias: [1.07932091]\t Cost: 0.1170546234022729\n",
            "Iteration: 197\t Weight: [1.85061583]\t Bias: [1.075065]\t Cost: 0.11613331850309964\n",
            "Iteration: 198\t Weight: [1.85120487]\t Bias: [1.07082587]\t Cost: 0.11521926494259738\n",
            "Iteration: 199\t Weight: [1.85179159]\t Bias: [1.06660346]\t Cost: 0.11431240564746352\n",
            "Iteration: 200\t Weight: [1.85237599]\t Bias: [1.0623977]\t Cost: 0.11341268399360513\n",
            "Iteration: 201\t Weight: [1.8529581]\t Bias: [1.05820852]\t Cost: 0.11252004380260133\n",
            "Iteration: 202\t Weight: [1.8535379]\t Bias: [1.05403586]\t Cost: 0.11163442933819669\n",
            "Iteration: 203\t Weight: [1.85411542]\t Bias: [1.04987965]\t Cost: 0.11075578530282006\n",
            "Iteration: 204\t Weight: [1.85469067]\t Bias: [1.04573983]\t Cost: 0.10988405683413266\n",
            "Iteration: 205\t Weight: [1.85526364]\t Bias: [1.04161633]\t Cost: 0.10901918950160205\n",
            "Iteration: 206\t Weight: [1.85583436]\t Bias: [1.0375091]\t Cost: 0.10816112930310387\n",
            "Iteration: 207\t Weight: [1.85640282]\t Bias: [1.03341806]\t Cost: 0.10730982266154916\n",
            "Iteration: 208\t Weight: [1.85696904]\t Bias: [1.02934315]\t Cost: 0.10646521642154004\n",
            "Iteration: 209\t Weight: [1.85753303]\t Bias: [1.0252843]\t Cost: 0.10562725784605012\n",
            "Iteration: 210\t Weight: [1.8580948]\t Bias: [1.02124147]\t Cost: 0.10479589461313138\n",
            "Iteration: 211\t Weight: [1.85865435]\t Bias: [1.01721457]\t Cost: 0.10397107481264838\n",
            "Iteration: 212\t Weight: [1.8592117]\t Bias: [1.01320356]\t Cost: 0.10315274694303508\n",
            "Iteration: 213\t Weight: [1.85976685]\t Bias: [1.00920836]\t Cost: 0.10234085990808046\n",
            "Iteration: 214\t Weight: [1.8603198]\t Bias: [1.00522891]\t Cost: 0.10153536301373857\n",
            "Iteration: 215\t Weight: [1.86087058]\t Bias: [1.00126515]\t Cost: 0.10073620596496162\n",
            "Iteration: 216\t Weight: [1.86141919]\t Bias: [0.99731703]\t Cost: 0.09994333886256043\n",
            "Iteration: 217\t Weight: [1.86196563]\t Bias: [0.99338447]\t Cost: 0.09915671220008898\n",
            "Iteration: 218\t Weight: [1.86250992]\t Bias: [0.98946742]\t Cost: 0.0983762768607524\n",
            "Iteration: 219\t Weight: [1.86305206]\t Bias: [0.98556581]\t Cost: 0.09760198411434179\n",
            "Iteration: 220\t Weight: [1.86359207]\t Bias: [0.98167959]\t Cost: 0.0968337856141893\n",
            "Iteration: 221\t Weight: [1.86412994]\t Bias: [0.97780869]\t Cost: 0.09607163339415076\n",
            "Iteration: 222\t Weight: [1.8646657]\t Bias: [0.97395306]\t Cost: 0.09531547986561044\n",
            "Iteration: 223\t Weight: [1.86519934]\t Bias: [0.97011263]\t Cost: 0.09456527781450969\n",
            "Iteration: 224\t Weight: [1.86573088]\t Bias: [0.96628734]\t Cost: 0.09382098039839849\n",
            "Iteration: 225\t Weight: [1.86626032]\t Bias: [0.96247714]\t Cost: 0.09308254114351171\n",
            "Iteration: 226\t Weight: [1.86678767]\t Bias: [0.95868196]\t Cost: 0.09234991394186486\n",
            "Iteration: 227\t Weight: [1.86731295]\t Bias: [0.95490174]\t Cost: 0.09162305304837894\n",
            "Iteration: 228\t Weight: [1.86783615]\t Bias: [0.95113643]\t Cost: 0.09090191307802023\n",
            "Iteration: 229\t Weight: [1.86835729]\t Bias: [0.94738597]\t Cost: 0.09018644900296885\n",
            "Iteration: 230\t Weight: [1.86887638]\t Bias: [0.9436503]\t Cost: 0.08947661614980683\n",
            "Iteration: 231\t Weight: [1.86939341]\t Bias: [0.93992936]\t Cost: 0.08877237019672772\n",
            "Iteration: 232\t Weight: [1.86990841]\t Bias: [0.93622309]\t Cost: 0.08807366717077057\n",
            "Iteration: 233\t Weight: [1.87042138]\t Bias: [0.93253143]\t Cost: 0.08738046344507325\n",
            "Iteration: 234\t Weight: [1.87093233]\t Bias: [0.92885433]\t Cost: 0.08669271573614848\n",
            "Iteration: 235\t Weight: [1.87144126]\t Bias: [0.92519173]\t Cost: 0.08601038110118203\n",
            "Iteration: 236\t Weight: [1.87194819]\t Bias: [0.92154357]\t Cost: 0.08533341693535035\n",
            "Iteration: 237\t Weight: [1.87245311]\t Bias: [0.9179098]\t Cost: 0.08466178096916102\n",
            "Iteration: 238\t Weight: [1.87295605]\t Bias: [0.91429036]\t Cost: 0.0839954312658132\n",
            "Iteration: 239\t Weight: [1.873457]\t Bias: [0.91068518]\t Cost: 0.08333432621857895\n",
            "Iteration: 240\t Weight: [1.87395597]\t Bias: [0.90709423]\t Cost: 0.08267842454820554\n",
            "Iteration: 241\t Weight: [1.87445298]\t Bias: [0.90351743]\t Cost: 0.08202768530033855\n",
            "Iteration: 242\t Weight: [1.87494803]\t Bias: [0.89995474]\t Cost: 0.08138206784296313\n",
            "Iteration: 243\t Weight: [1.87544113]\t Bias: [0.89640609]\t Cost: 0.08074153186386823\n",
            "Iteration: 244\t Weight: [1.87593228]\t Bias: [0.89287144]\t Cost: 0.08010603736812953\n",
            "Iteration: 245\t Weight: [1.8764215]\t Bias: [0.88935072]\t Cost: 0.07947554467561127\n",
            "Iteration: 246\t Weight: [1.87690878]\t Bias: [0.88584389]\t Cost: 0.07885001441848986\n",
            "Iteration: 247\t Weight: [1.87739415]\t Bias: [0.88235089]\t Cost: 0.0782294075387943\n",
            "Iteration: 248\t Weight: [1.8778776]\t Bias: [0.87887166]\t Cost: 0.07761368528596883\n",
            "Iteration: 249\t Weight: [1.87835915]\t Bias: [0.87540615]\t Cost: 0.07700280921445217\n",
            "Iteration: 250\t Weight: [1.87883879]\t Bias: [0.8719543]\t Cost: 0.07639674118127773\n",
            "Iteration: 251\t Weight: [1.87931655]\t Bias: [0.86851606]\t Cost: 0.07579544334369243\n",
            "Iteration: 252\t Weight: [1.87979242]\t Bias: [0.86509139]\t Cost: 0.0751988781567921\n",
            "Iteration: 253\t Weight: [1.88026642]\t Bias: [0.86168021]\t Cost: 0.07460700837117865\n",
            "Iteration: 254\t Weight: [1.88073854]\t Bias: [0.85828249]\t Cost: 0.07401979703063392\n",
            "Iteration: 255\t Weight: [1.88120881]\t Bias: [0.85489816]\t Cost: 0.0734372074698119\n",
            "Iteration: 256\t Weight: [1.88167722]\t Bias: [0.85152718]\t Cost: 0.07285920331194944\n",
            "Iteration: 257\t Weight: [1.88214378]\t Bias: [0.84816949]\t Cost: 0.07228574846659518\n",
            "Iteration: 258\t Weight: [1.8826085]\t Bias: [0.84482504]\t Cost: 0.07171680712735587\n",
            "Iteration: 259\t Weight: [1.88307139]\t Bias: [0.84149378]\t Cost: 0.07115234376965976\n",
            "Iteration: 260\t Weight: [1.88353246]\t Bias: [0.83817566]\t Cost: 0.07059232314854055\n",
            "Iteration: 261\t Weight: [1.88399171]\t Bias: [0.83487062]\t Cost: 0.07003671029643417\n",
            "Iteration: 262\t Weight: [1.88444914]\t Bias: [0.83157861]\t Cost: 0.06948547052099788\n",
            "Iteration: 263\t Weight: [1.88490478]\t Bias: [0.82829958]\t Cost: 0.06893856940294175\n",
            "Iteration: 264\t Weight: [1.88535861]\t Bias: [0.82503348]\t Cost: 0.06839597279388135\n",
            "Iteration: 265\t Weight: [1.88581066]\t Bias: [0.82178026]\t Cost: 0.06785764681420475\n",
            "Iteration: 266\t Weight: [1.88626092]\t Bias: [0.81853987]\t Cost: 0.06732355785095696\n",
            "Iteration: 267\t Weight: [1.88670941]\t Bias: [0.81531225]\t Cost: 0.06679367255574165\n",
            "Iteration: 268\t Weight: [1.88715613]\t Bias: [0.81209736]\t Cost: 0.06626795784263789\n",
            "Iteration: 269\t Weight: [1.88760109]\t Bias: [0.80889515]\t Cost: 0.06574638088613621\n",
            "Iteration: 270\t Weight: [1.8880443]\t Bias: [0.80570557]\t Cost: 0.06522890911908664\n",
            "Iteration: 271\t Weight: [1.88848575]\t Bias: [0.80252856]\t Cost: 0.06471551023066692\n",
            "Iteration: 272\t Weight: [1.88892547]\t Bias: [0.79936408]\t Cost: 0.06420615216436383\n",
            "Iteration: 273\t Weight: [1.88936345]\t Bias: [0.79621208]\t Cost: 0.06370080311597309\n",
            "Iteration: 274\t Weight: [1.88979971]\t Bias: [0.7930725]\t Cost: 0.0631994315316121\n",
            "Iteration: 275\t Weight: [1.89023424]\t Bias: [0.78994531]\t Cost: 0.06270200610574976\n",
            "Iteration: 276\t Weight: [1.89066706]\t Bias: [0.78683045]\t Cost: 0.062208495779253\n",
            "Iteration: 277\t Weight: [1.89109818]\t Bias: [0.78372787]\t Cost: 0.06171886973744637\n",
            "Iteration: 278\t Weight: [1.89152759]\t Bias: [0.78063752]\t Cost: 0.06123309740818857\n",
            "Iteration: 279\t Weight: [1.89195531]\t Bias: [0.77755936]\t Cost: 0.06075114845996283\n",
            "Iteration: 280\t Weight: [1.89238135]\t Bias: [0.77449333]\t Cost: 0.06027299279998325\n",
            "Iteration: 281\t Weight: [1.8928057]\t Bias: [0.7714394]\t Cost: 0.05979860057231688\n",
            "Iteration: 282\t Weight: [1.89322838]\t Bias: [0.76839751]\t Cost: 0.059327942156018096\n",
            "Iteration: 283\t Weight: [1.8936494]\t Bias: [0.76536761]\t Cost: 0.058860988163279476\n",
            "Iteration: 284\t Weight: [1.89406875]\t Bias: [0.76234966]\t Cost: 0.058397709437597554\n",
            "Iteration: 285\t Weight: [1.89448646]\t Bias: [0.75934361]\t Cost: 0.05793807705195106\n",
            "Iteration: 286\t Weight: [1.89490251]\t Bias: [0.75634942]\t Cost: 0.057482062306995804\n",
            "Iteration: 287\t Weight: [1.89531692]\t Bias: [0.75336703]\t Cost: 0.057029636729272006\n",
            "Iteration: 288\t Weight: [1.8957297]\t Bias: [0.7503964]\t Cost: 0.05658077206942707\n",
            "Iteration: 289\t Weight: [1.89614086]\t Bias: [0.74743748]\t Cost: 0.05613544030045117\n",
            "Iteration: 290\t Weight: [1.89655039]\t Bias: [0.74449023]\t Cost: 0.05569361361592706\n",
            "Iteration: 291\t Weight: [1.8969583]\t Bias: [0.74155461]\t Cost: 0.05525526442829466\n",
            "Iteration: 292\t Weight: [1.89736461]\t Bias: [0.73863056]\t Cost: 0.05482036536712784\n",
            "Iteration: 293\t Weight: [1.89776932]\t Bias: [0.73571803]\t Cost: 0.05438888927742562\n",
            "Iteration: 294\t Weight: [1.89817243]\t Bias: [0.732817]\t Cost: 0.05396080921791628\n",
            "Iteration: 295\t Weight: [1.89857395]\t Bias: [0.7299274]\t Cost: 0.05353609845937618\n",
            "Iteration: 296\t Weight: [1.89897388]\t Bias: [0.72704919]\t Cost: 0.0531147304829594\n",
            "Iteration: 297\t Weight: [1.89937224]\t Bias: [0.72418234]\t Cost: 0.05269667897854315\n",
            "Iteration: 298\t Weight: [1.89976903]\t Bias: [0.72132679]\t Cost: 0.052281917843083926\n",
            "Iteration: 299\t Weight: [1.90016426]\t Bias: [0.7184825]\t Cost: 0.05187042117898831\n",
            "Iteration: 300\t Weight: [1.90055792]\t Bias: [0.71564942]\t Cost: 0.05146216329249607\n",
            "Iteration: 301\t Weight: [1.90095004]\t Bias: [0.71282752]\t Cost: 0.051057118692074854\n",
            "Iteration: 302\t Weight: [1.9013406]\t Bias: [0.71001674]\t Cost: 0.05065526208682994\n",
            "Iteration: 303\t Weight: [1.90172963]\t Bias: [0.70721705]\t Cost: 0.0502565683849236\n",
            "Iteration: 304\t Weight: [1.90211712]\t Bias: [0.7044284]\t Cost: 0.04986101269200984\n",
            "Iteration: 305\t Weight: [1.90250309]\t Bias: [0.70165074]\t Cost: 0.04946857030967853\n",
            "Iteration: 306\t Weight: [1.90288753]\t Bias: [0.69888403]\t Cost: 0.04907921673391442\n",
            "Iteration: 307\t Weight: [1.90327046]\t Bias: [0.69612824]\t Cost: 0.048692927653566614\n",
            "Iteration: 308\t Weight: [1.90365188]\t Bias: [0.69338331]\t Cost: 0.0483096789488304\n",
            "Iteration: 309\t Weight: [1.90403179]\t Bias: [0.6906492]\t Cost: 0.04792944668974152\n",
            "Iteration: 310\t Weight: [1.90441021]\t Bias: [0.68792588]\t Cost: 0.04755220713468221\n",
            "Iteration: 311\t Weight: [1.90478713]\t Bias: [0.68521329]\t Cost: 0.04717793672889814\n",
            "Iteration: 312\t Weight: [1.90516257]\t Bias: [0.6825114]\t Cost: 0.046806612103028125\n",
            "Iteration: 313\t Weight: [1.90553653]\t Bias: [0.67982016]\t Cost: 0.046438210071644746\n",
            "Iteration: 314\t Weight: [1.90590901]\t Bias: [0.67713954]\t Cost: 0.04607270763180682\n",
            "Iteration: 315\t Weight: [1.90628002]\t Bias: [0.67446949]\t Cost: 0.04571008196162331\n",
            "Iteration: 316\t Weight: [1.90664957]\t Bias: [0.67180996]\t Cost: 0.045350310418827276\n",
            "Iteration: 317\t Weight: [1.90701767]\t Bias: [0.66916092]\t Cost: 0.04499337053936328\n",
            "Iteration: 318\t Weight: [1.90738431]\t Bias: [0.66652233]\t Cost: 0.044639240035984934\n",
            "Iteration: 319\t Weight: [1.90774951]\t Bias: [0.66389414]\t Cost: 0.044287896796861674\n",
            "Iteration: 320\t Weight: [1.90811326]\t Bias: [0.66127631]\t Cost: 0.043939318884199455\n",
            "Iteration: 321\t Weight: [1.90847558]\t Bias: [0.65866881]\t Cost: 0.04359348453287076\n",
            "Iteration: 322\t Weight: [1.90883648]\t Bias: [0.65607159]\t Cost: 0.043250372149055395\n",
            "Iteration: 323\t Weight: [1.90919595]\t Bias: [0.65348461]\t Cost: 0.04290996030889222\n",
            "Iteration: 324\t Weight: [1.909554]\t Bias: [0.65090783]\t Cost: 0.04257222775714134\n",
            "Iteration: 325\t Weight: [1.90991064]\t Bias: [0.64834121]\t Cost: 0.04223715340585684\n",
            "Iteration: 326\t Weight: [1.91026588]\t Bias: [0.64578471]\t Cost: 0.041904716333070635\n",
            "Iteration: 327\t Weight: [1.91061971]\t Bias: [0.64323829]\t Cost: 0.04157489578148558\n",
            "Iteration: 328\t Weight: [1.91097215]\t Bias: [0.64070192]\t Cost: 0.04124767115717965\n",
            "Iteration: 329\t Weight: [1.9113232]\t Bias: [0.63817554]\t Cost: 0.04092302202831946\n",
            "Iteration: 330\t Weight: [1.91167286]\t Bias: [0.63565913]\t Cost: 0.04060092812388583\n",
            "Iteration: 331\t Weight: [1.91202115]\t Bias: [0.63315264]\t Cost: 0.04028136933240642\n",
            "Iteration: 332\t Weight: [1.91236806]\t Bias: [0.63065603]\t Cost: 0.03996432570070133\n",
            "Iteration: 333\t Weight: [1.91271361]\t Bias: [0.62816926]\t Cost: 0.03964977743263616\n",
            "Iteration: 334\t Weight: [1.91305779]\t Bias: [0.62569231]\t Cost: 0.03933770488788685\n",
            "Iteration: 335\t Weight: [1.91340061]\t Bias: [0.62322512]\t Cost: 0.03902808858071304\n",
            "Iteration: 336\t Weight: [1.91374209]\t Bias: [0.62076765]\t Cost: 0.03872090917874103\n",
            "Iteration: 337\t Weight: [1.91408221]\t Bias: [0.61831988]\t Cost: 0.03841614750175692\n",
            "Iteration: 338\t Weight: [1.914421]\t Bias: [0.61588176]\t Cost: 0.038113784520509446\n",
            "Iteration: 339\t Weight: [1.91475845]\t Bias: [0.61345326]\t Cost: 0.03781380135552084\n",
            "Iteration: 340\t Weight: [1.91509457]\t Bias: [0.61103433]\t Cost: 0.03751617927590864\n",
            "Iteration: 341\t Weight: [1.91542936]\t Bias: [0.60862493]\t Cost: 0.03722089969821632\n",
            "Iteration: 342\t Weight: [1.91576284]\t Bias: [0.60622504]\t Cost: 0.0369279441852526\n",
            "Iteration: 343\t Weight: [1.91609499]\t Bias: [0.60383461]\t Cost: 0.03663729444494003\n",
            "Iteration: 344\t Weight: [1.91642584]\t Bias: [0.60145361]\t Cost: 0.03634893232917308\n",
            "Iteration: 345\t Weight: [1.91675539]\t Bias: [0.599082]\t Cost: 0.03606283983268549\n",
            "Iteration: 346\t Weight: [1.91708363]\t Bias: [0.59671973]\t Cost: 0.03577899909192506\n",
            "Iteration: 347\t Weight: [1.91741058]\t Bias: [0.59436679]\t Cost: 0.03549739238393859\n",
            "Iteration: 348\t Weight: [1.91773625]\t Bias: [0.59202312]\t Cost: 0.035218002125266\n",
            "Iteration: 349\t Weight: [1.91806062]\t Bias: [0.58968869]\t Cost: 0.03494081087084137\n",
            "Iteration: 350\t Weight: [1.91838372]\t Bias: [0.58736346]\t Cost: 0.03466580131290396\n",
            "Iteration: 351\t Weight: [1.91870554]\t Bias: [0.58504741]\t Cost: 0.03439295627991811\n",
            "Iteration: 352\t Weight: [1.9190261]\t Bias: [0.58274049]\t Cost: 0.03412225873550031\n",
            "Iteration: 353\t Weight: [1.91934539]\t Bias: [0.58044266]\t Cost: 0.03385369177735617\n",
            "Iteration: 354\t Weight: [1.91966342]\t Bias: [0.5781539]\t Cost: 0.03358723863622407\n",
            "Iteration: 355\t Weight: [1.9199802]\t Bias: [0.57587416]\t Cost: 0.033322882674828906\n",
            "Iteration: 356\t Weight: [1.92029573]\t Bias: [0.5736034]\t Cost: 0.03306060738684331\n",
            "Iteration: 357\t Weight: [1.92061002]\t Bias: [0.57134161]\t Cost: 0.03280039639585605\n",
            "Iteration: 358\t Weight: [1.92092306]\t Bias: [0.56908873]\t Cost: 0.032542233454350936\n",
            "Iteration: 359\t Weight: [1.92123487]\t Bias: [0.56684473]\t Cost: 0.03228610244269061\n",
            "Iteration: 360\t Weight: [1.92154545]\t Bias: [0.56460959]\t Cost: 0.03203198736811193\n",
            "Iteration: 361\t Weight: [1.92185481]\t Bias: [0.56238325]\t Cost: 0.03177987236372575\n",
            "Iteration: 362\t Weight: [1.92216295]\t Bias: [0.5601657]\t Cost: 0.031529741687527056\n",
            "Iteration: 363\t Weight: [1.92246987]\t Bias: [0.55795689]\t Cost: 0.03128157972141186\n",
            "Iteration: 364\t Weight: [1.92277558]\t Bias: [0.55575679]\t Cost: 0.03103537097020198\n",
            "Iteration: 365\t Weight: [1.92308009]\t Bias: [0.55356536]\t Cost: 0.030791100060677763\n",
            "Iteration: 366\t Weight: [1.92338339]\t Bias: [0.55138258]\t Cost: 0.030548751740617455\n",
            "Iteration: 367\t Weight: [1.9236855]\t Bias: [0.5492084]\t Cost: 0.030308310877845777\n",
            "Iteration: 368\t Weight: [1.92398642]\t Bias: [0.5470428]\t Cost: 0.030069762459288718\n",
            "Iteration: 369\t Weight: [1.92428616]\t Bias: [0.54488573]\t Cost: 0.02983309159003558\n",
            "Iteration: 370\t Weight: [1.92458471]\t Bias: [0.54273717]\t Cost: 0.029598283492409862\n",
            "Iteration: 371\t Weight: [1.92488208]\t Bias: [0.54059709]\t Cost: 0.029365323505046156\n",
            "Iteration: 372\t Weight: [1.92517828]\t Bias: [0.53846544]\t Cost: 0.029134197081974123\n",
            "Iteration: 373\t Weight: [1.92547331]\t Bias: [0.5363422]\t Cost: 0.028904889791711495\n",
            "Iteration: 374\t Weight: [1.92576718]\t Bias: [0.53422732]\t Cost: 0.028677387316361658\n",
            "Iteration: 375\t Weight: [1.92605989]\t Bias: [0.53212079]\t Cost: 0.028451675450720484\n",
            "Iteration: 376\t Weight: [1.92635145]\t Bias: [0.53002257]\t Cost: 0.028227740101389145\n",
            "Iteration: 377\t Weight: [1.92664185]\t Bias: [0.52793262]\t Cost: 0.0280055672858942\n",
            "Iteration: 378\t Weight: [1.92693111]\t Bias: [0.5258509]\t Cost: 0.027785143131814034\n",
            "Iteration: 379\t Weight: [1.92721923]\t Bias: [0.5237774]\t Cost: 0.027566453875913378\n",
            "Iteration: 380\t Weight: [1.92750622]\t Bias: [0.52171208]\t Cost: 0.027349485863283715\n",
            "Iteration: 381\t Weight: [1.92779207]\t Bias: [0.51965489]\t Cost: 0.027134225546490375\n",
            "Iteration: 382\t Weight: [1.9280768]\t Bias: [0.51760582]\t Cost: 0.026920659484726765\n",
            "Iteration: 383\t Weight: [1.9283604]\t Bias: [0.51556483]\t Cost: 0.026708774342975403\n",
            "Iteration: 384\t Weight: [1.92864289]\t Bias: [0.51353189]\t Cost: 0.02649855689117477\n",
            "Iteration: 385\t Weight: [1.92892426]\t Bias: [0.51150696]\t Cost: 0.026289994003394254\n",
            "Iteration: 386\t Weight: [1.92920452]\t Bias: [0.50949002]\t Cost: 0.0260830726570129\n",
            "Iteration: 387\t Weight: [1.92948367]\t Bias: [0.50748103]\t Cost: 0.025877779931907947\n",
            "Iteration: 388\t Weight: [1.92976173]\t Bias: [0.50547996]\t Cost: 0.02567410300964689\n",
            "Iteration: 389\t Weight: [1.93003869]\t Bias: [0.50348679]\t Cost: 0.0254720291726882\n",
            "Iteration: 390\t Weight: [1.93031456]\t Bias: [0.50150147]\t Cost: 0.025271545803586003\n",
            "Iteration: 391\t Weight: [1.93058933]\t Bias: [0.49952398]\t Cost: 0.025072640384203135\n",
            "Iteration: 392\t Weight: [1.93086303]\t Bias: [0.49755429]\t Cost: 0.024875300494929618\n",
            "Iteration: 393\t Weight: [1.93113565]\t Bias: [0.49559236]\t Cost: 0.024679513813906165\n",
            "Iteration: 394\t Weight: [1.93140719]\t Bias: [0.49363818]\t Cost: 0.024485268116255825\n",
            "Iteration: 395\t Weight: [1.93167766]\t Bias: [0.49169169]\t Cost: 0.024292551273320556\n",
            "Iteration: 396\t Weight: [1.93194706]\t Bias: [0.48975288]\t Cost: 0.024101351251903144\n",
            "Iteration: 397\t Weight: [1.93221541]\t Bias: [0.48782172]\t Cost: 0.023911656113516682\n",
            "Iteration: 398\t Weight: [1.93248269]\t Bias: [0.48589817]\t Cost: 0.023723454013638744\n",
            "Iteration: 399\t Weight: [1.93274892]\t Bias: [0.48398221]\t Cost: 0.023536733200972097\n",
            "Iteration: 400\t Weight: [1.9330141]\t Bias: [0.4820738]\t Cost: 0.023351482016710393\n",
            "Iteration: 401\t Weight: [1.93327823]\t Bias: [0.48017292]\t Cost: 0.023167688893810726\n",
            "Iteration: 402\t Weight: [1.93354133]\t Bias: [0.47827953]\t Cost: 0.022985342356271234\n",
            "Iteration: 403\t Weight: [1.93380338]\t Bias: [0.47639361]\t Cost: 0.022804431018414714\n",
            "Iteration: 404\t Weight: [1.93406441]\t Bias: [0.47451512]\t Cost: 0.02262494358417709\n",
            "Iteration: 405\t Weight: [1.9343244]\t Bias: [0.47264405]\t Cost: 0.02244686884640293\n",
            "Iteration: 406\t Weight: [1.93458337]\t Bias: [0.47078035]\t Cost: 0.022270195686144887\n",
            "Iteration: 407\t Weight: [1.93484131]\t Bias: [0.46892399]\t Cost: 0.022094913071970222\n",
            "Iteration: 408\t Weight: [1.93509824]\t Bias: [0.46707496]\t Cost: 0.021921010059271148\n",
            "Iteration: 409\t Weight: [1.93535416]\t Bias: [0.46523322]\t Cost: 0.021748475789582257\n",
            "Iteration: 410\t Weight: [1.93560907]\t Bias: [0.46339874]\t Cost: 0.02157729948990181\n",
            "Iteration: 411\t Weight: [1.93586297]\t Bias: [0.4615715]\t Cost: 0.02140747047201971\n",
            "Iteration: 412\t Weight: [1.93611587]\t Bias: [0.45975146]\t Cost: 0.021238978131849565\n",
            "Iteration: 413\t Weight: [1.93636777]\t Bias: [0.4579386]\t Cost: 0.02107181194876717\n",
            "Iteration: 414\t Weight: [1.93661869]\t Bias: [0.45613288]\t Cost: 0.020905961484953193\n",
            "Iteration: 415\t Weight: [1.93686861]\t Bias: [0.45433429]\t Cost: 0.02074141638474107\n",
            "Iteration: 416\t Weight: [1.93711754]\t Bias: [0.45254278]\t Cost: 0.020578166373971404\n",
            "Iteration: 417\t Weight: [1.9373655]\t Bias: [0.45075834]\t Cost: 0.020416201259349863\n",
            "Iteration: 418\t Weight: [1.93761247]\t Bias: [0.44898094]\t Cost: 0.020255510927810378\n",
            "Iteration: 419\t Weight: [1.93785848]\t Bias: [0.44721055]\t Cost: 0.020096085345884314\n",
            "Iteration: 420\t Weight: [1.93810351]\t Bias: [0.44544714]\t Cost: 0.019937914559073705\n",
            "Iteration: 421\t Weight: [1.93834757]\t Bias: [0.44369068]\t Cost: 0.019780988691229583\n",
            "Iteration: 422\t Weight: [1.93859068]\t Bias: [0.44194114]\t Cost: 0.019625297943935614\n",
            "Iteration: 423\t Weight: [1.93883282]\t Bias: [0.44019851]\t Cost: 0.01947083259589595\n",
            "Iteration: 424\t Weight: [1.93907401]\t Bias: [0.43846275]\t Cost: 0.019317583002328616\n",
            "Iteration: 425\t Weight: [1.93931425]\t Bias: [0.43673383]\t Cost: 0.019165539594362898\n",
            "Iteration: 426\t Weight: [1.93955355]\t Bias: [0.43501173]\t Cost: 0.019014692878442124\n",
            "Iteration: 427\t Weight: [1.93979189]\t Bias: [0.43329642]\t Cost: 0.01886503343573069\n",
            "Iteration: 428\t Weight: [1.9400293]\t Bias: [0.43158787]\t Cost: 0.01871655192152609\n",
            "Iteration: 429\t Weight: [1.94026578]\t Bias: [0.42988606]\t Cost: 0.01856923906467581\n",
            "Iteration: 430\t Weight: [1.94050132]\t Bias: [0.42819096]\t Cost: 0.01842308566699753\n",
            "Iteration: 431\t Weight: [1.94073593]\t Bias: [0.42650254]\t Cost: 0.018278082602705362\n",
            "Iteration: 432\t Weight: [1.94096961]\t Bias: [0.42482078]\t Cost: 0.01813422081784037\n",
            "Iteration: 433\t Weight: [1.94120238]\t Bias: [0.42314566]\t Cost: 0.017991491329704255\n",
            "Iteration: 434\t Weight: [1.94143423]\t Bias: [0.42147714]\t Cost: 0.017849885226299725\n",
            "Iteration: 435\t Weight: [1.94166516]\t Bias: [0.41981519]\t Cost: 0.01770939366577292\n",
            "Iteration: 436\t Weight: [1.94189518]\t Bias: [0.4181598]\t Cost: 0.017570007875861857\n",
            "Iteration: 437\t Weight: [1.9421243]\t Bias: [0.41651094]\t Cost: 0.017431719153348943\n",
            "Iteration: 438\t Weight: [1.94235251]\t Bias: [0.41486858]\t Cost: 0.01729451886351662\n",
            "Iteration: 439\t Weight: [1.94257982]\t Bias: [0.4132327]\t Cost: 0.01715839843960968\n",
            "Iteration: 440\t Weight: [1.94280624]\t Bias: [0.41160327]\t Cost: 0.01702334938229867\n",
            "Iteration: 441\t Weight: [1.94303176]\t Bias: [0.40998026]\t Cost: 0.016889363259150414\n",
            "Iteration: 442\t Weight: [1.94325639]\t Bias: [0.40836365]\t Cost: 0.016756431704101144\n",
            "Iteration: 443\t Weight: [1.94348014]\t Bias: [0.40675342]\t Cost: 0.016624546416934054\n",
            "Iteration: 444\t Weight: [1.94370301]\t Bias: [0.40514953]\t Cost: 0.016493699162760913\n",
            "Iteration: 445\t Weight: [1.94392499]\t Bias: [0.40355197]\t Cost: 0.01636388177150838\n",
            "Iteration: 446\t Weight: [1.9441461]\t Bias: [0.40196071]\t Cost: 0.016235086137407137\n",
            "Iteration: 447\t Weight: [1.94436634]\t Bias: [0.40037572]\t Cost: 0.016107304218486405\n",
            "Iteration: 448\t Weight: [1.94458572]\t Bias: [0.39879699]\t Cost: 0.0159805280360714\n",
            "Iteration: 449\t Weight: [1.94480422]\t Bias: [0.39722448]\t Cost: 0.0158547496742855\n",
            "Iteration: 450\t Weight: [1.94502187]\t Bias: [0.39565817]\t Cost: 0.015729961279555525\n",
            "Iteration: 451\t Weight: [1.94523865]\t Bias: [0.39409803]\t Cost: 0.015606155060121982\n",
            "Iteration: 452\t Weight: [1.94545458]\t Bias: [0.39254405]\t Cost: 0.015483323285551806\n",
            "Iteration: 453\t Weight: [1.94566966]\t Bias: [0.39099619]\t Cost: 0.015361458286256279\n",
            "Iteration: 454\t Weight: [1.9458839]\t Bias: [0.38945444]\t Cost: 0.015240552453011829\n",
            "Iteration: 455\t Weight: [1.94609728]\t Bias: [0.38791877]\t Cost: 0.015120598236484931\n",
            "Iteration: 456\t Weight: [1.94630983]\t Bias: [0.38638915]\t Cost: 0.01500158814676111\n",
            "Iteration: 457\t Weight: [1.94652154]\t Bias: [0.38486557]\t Cost: 0.014883514752876506\n",
            "Iteration: 458\t Weight: [1.94673241]\t Bias: [0.38334799]\t Cost: 0.014766370682354701\n",
            "Iteration: 459\t Weight: [1.94694245]\t Bias: [0.3818364]\t Cost: 0.014650148620745838\n",
            "Iteration: 460\t Weight: [1.94715166]\t Bias: [0.38033076]\t Cost: 0.014534841311170202\n",
            "Iteration: 461\t Weight: [1.94736005]\t Bias: [0.37883107]\t Cost: 0.014420441553864948\n",
            "Iteration: 462\t Weight: [1.94756762]\t Bias: [0.37733728]\t Cost: 0.01430694220573443\n",
            "Iteration: 463\t Weight: [1.94777437]\t Bias: [0.37584939]\t Cost: 0.014194336179904728\n",
            "Iteration: 464\t Weight: [1.9479803]\t Bias: [0.37436736]\t Cost: 0.014082616445280373\n",
            "Iteration: 465\t Weight: [1.94818542]\t Bias: [0.37289118]\t Cost: 0.013971776026105998\n",
            "Iteration: 466\t Weight: [1.94838973]\t Bias: [0.37142082]\t Cost: 0.013861808001530215\n",
            "Iteration: 467\t Weight: [1.94859324]\t Bias: [0.36995626]\t Cost: 0.01375270550517422\n",
            "Iteration: 468\t Weight: [1.94879594]\t Bias: [0.36849747]\t Cost: 0.01364446172470208\n",
            "Iteration: 469\t Weight: [1.94899785]\t Bias: [0.36704443]\t Cost: 0.013537069901396269\n",
            "Iteration: 470\t Weight: [1.94919896]\t Bias: [0.36559713]\t Cost: 0.01343052332973501\n",
            "Iteration: 471\t Weight: [1.94939927]\t Bias: [0.36415553]\t Cost: 0.013324815356974211\n",
            "Iteration: 472\t Weight: [1.9495988]\t Bias: [0.36271961]\t Cost: 0.013219939382731243\n",
            "Iteration: 473\t Weight: [1.94979754]\t Bias: [0.36128936]\t Cost: 0.013115888858573559\n",
            "Iteration: 474\t Weight: [1.94999549]\t Bias: [0.35986475]\t Cost: 0.013012657287609657\n",
            "Iteration: 475\t Weight: [1.95019267]\t Bias: [0.35844575]\t Cost: 0.012910238224082903\n",
            "Iteration: 476\t Weight: [1.95038906]\t Bias: [0.35703235]\t Cost: 0.01280862527296981\n",
            "Iteration: 477\t Weight: [1.95058469]\t Bias: [0.35562452]\t Cost: 0.012707812089580097\n",
            "Iteration: 478\t Weight: [1.95077954]\t Bias: [0.35422224]\t Cost: 0.01260779237916114\n",
            "Iteration: 479\t Weight: [1.95097362]\t Bias: [0.3528255]\t Cost: 0.012508559896504236\n",
            "Iteration: 480\t Weight: [1.95116694]\t Bias: [0.35143426]\t Cost: 0.012410108445555195\n",
            "Iteration: 481\t Weight: [1.95135949]\t Bias: [0.3500485]\t Cost: 0.012312431879027218\n",
            "Iteration: 482\t Weight: [1.95155129]\t Bias: [0.34866822]\t Cost: 0.012215524098017176\n",
            "Iteration: 483\t Weight: [1.95174233]\t Bias: [0.34729337]\t Cost: 0.01211937905162464\n",
            "Iteration: 484\t Weight: [1.95193262]\t Bias: [0.34592394]\t Cost: 0.012023990736574229\n",
            "Iteration: 485\t Weight: [1.95212215]\t Bias: [0.34455992]\t Cost: 0.011929353196840846\n",
            "Iteration: 486\t Weight: [1.95231094]\t Bias: [0.34320127]\t Cost: 0.011835460523277263\n",
            "Iteration: 487\t Weight: [1.95249899]\t Bias: [0.34184798]\t Cost: 0.011742306853245857\n",
            "Iteration: 488\t Weight: [1.95268629]\t Bias: [0.34050003]\t Cost: 0.011649886370252086\n",
            "Iteration: 489\t Weight: [1.95287285]\t Bias: [0.33915739]\t Cost: 0.011558193303581595\n",
            "Iteration: 490\t Weight: [1.95305868]\t Bias: [0.33782004]\t Cost: 0.01146722192793934\n",
            "Iteration: 491\t Weight: [1.95324378]\t Bias: [0.33648797]\t Cost: 0.011376966563093142\n",
            "Iteration: 492\t Weight: [1.95342814]\t Bias: [0.33516116]\t Cost: 0.011287421573517786\n",
            "Iteration: 493\t Weight: [1.95361178]\t Bias: [0.33383957]\t Cost: 0.011198581368043942\n",
            "Iteration: 494\t Weight: [1.9537947]\t Bias: [0.33252319]\t Cost: 0.011110440399509048\n",
            "Iteration: 495\t Weight: [1.95397689]\t Bias: [0.33121201]\t Cost: 0.011022993164410452\n",
            "Iteration: 496\t Weight: [1.95415837]\t Bias: [0.329906]\t Cost: 0.010936234202562185\n",
            "Iteration: 497\t Weight: [1.95433913]\t Bias: [0.32860513]\t Cost: 0.010850158096753864\n",
            "Iteration: 498\t Weight: [1.95451917]\t Bias: [0.3273094]\t Cost: 0.010764759472412615\n",
            "Iteration: 499\t Weight: [1.95469851]\t Bias: [0.32601877]\t Cost: 0.010680032997267162\n",
            "Iteration: 500\t Weight: [1.95487714]\t Bias: [0.32473323]\t Cost: 0.010595973381015237\n",
            "Iteration: 501\t Weight: [1.95505507]\t Bias: [0.32345276]\t Cost: 0.010512575374992943\n",
            "Iteration: 502\t Weight: [1.95523229]\t Bias: [0.32217735]\t Cost: 0.010429833771847337\n",
            "Iteration: 503\t Weight: [1.95540882]\t Bias: [0.32090696]\t Cost: 0.01034774340521107\n",
            "Iteration: 504\t Weight: [1.95558465]\t Bias: [0.31964158]\t Cost: 0.010266299149379838\n",
            "Iteration: 505\t Weight: [1.95575978]\t Bias: [0.31838119]\t Cost: 0.010185495918992309\n",
            "Iteration: 506\t Weight: [1.95593423]\t Bias: [0.31712577]\t Cost: 0.01010532866871267\n",
            "Iteration: 507\t Weight: [1.95610798]\t Bias: [0.31587529]\t Cost: 0.01002579239291566\n",
            "Iteration: 508\t Weight: [1.95628106]\t Bias: [0.31462976]\t Cost: 0.009946882125373849\n",
            "Iteration: 509\t Weight: [1.95645345]\t Bias: [0.31338913]\t Cost: 0.009868592938947473\n",
            "Iteration: 510\t Weight: [1.95662516]\t Bias: [0.31215339]\t Cost: 0.009790919945277279\n",
            "Iteration: 511\t Weight: [1.95679619]\t Bias: [0.31092253]\t Cost: 0.009713858294478591\n",
            "Iteration: 512\t Weight: [1.95696655]\t Bias: [0.30969652]\t Cost: 0.009637403174839096\n",
            "Iteration: 513\t Weight: [1.95713623]\t Bias: [0.30847534]\t Cost: 0.009561549812518142\n",
            "Iteration: 514\t Weight: [1.95730525]\t Bias: [0.30725898]\t Cost: 0.009486293471248353\n",
            "Iteration: 515\t Weight: [1.9574736]\t Bias: [0.30604742]\t Cost: 0.009411629452040686\n",
            "Iteration: 516\t Weight: [1.95764129]\t Bias: [0.30484063]\t Cost: 0.009337553092890234\n",
            "Iteration: 517\t Weight: [1.95780832]\t Bias: [0.3036386]\t Cost: 0.009264059768485601\n",
            "Iteration: 518\t Weight: [1.95797469]\t Bias: [0.30244131]\t Cost: 0.009191144889919784\n",
            "Iteration: 519\t Weight: [1.9581404]\t Bias: [0.30124874]\t Cost: 0.009118803904404114\n",
            "Iteration: 520\t Weight: [1.95830545]\t Bias: [0.30006088]\t Cost: 0.009047032294983347\n",
            "Iteration: 521\t Weight: [1.95846986]\t Bias: [0.2988777]\t Cost: 0.008975825580254043\n",
            "Iteration: 522\t Weight: [1.95863362]\t Bias: [0.29769918]\t Cost: 0.008905179314084915\n",
            "Iteration: 523\t Weight: [1.95879673]\t Bias: [0.29652531]\t Cost: 0.008835089085338563\n",
            "Iteration: 524\t Weight: [1.9589592]\t Bias: [0.29535607]\t Cost: 0.0087655505175967\n",
            "Iteration: 525\t Weight: [1.95912103]\t Bias: [0.29419144]\t Cost: 0.00869655926888665\n",
            "Iteration: 526\t Weight: [1.95928223]\t Bias: [0.29303141]\t Cost: 0.008628111031410023\n",
            "Iteration: 527\t Weight: [1.95944278]\t Bias: [0.29187594]\t Cost: 0.00856020153127411\n",
            "Iteration: 528\t Weight: [1.9596027]\t Bias: [0.29072504]\t Cost: 0.008492826528224777\n",
            "Iteration: 529\t Weight: [1.959762]\t Bias: [0.28957867]\t Cost: 0.00842598181538169\n",
            "Iteration: 530\t Weight: [1.95992066]\t Bias: [0.28843682]\t Cost: 0.008359663218975834\n",
            "Iteration: 531\t Weight: [1.9600787]\t Bias: [0.28729947]\t Cost: 0.008293866598088727\n",
            "Iteration: 532\t Weight: [1.96023611]\t Bias: [0.28616661]\t Cost: 0.008228587844394002\n",
            "Iteration: 533\t Weight: [1.96039291]\t Bias: [0.28503822]\t Cost: 0.008163822881900654\n",
            "Iteration: 534\t Weight: [1.96054908]\t Bias: [0.28391427]\t Cost: 0.008099567666698969\n",
            "Iteration: 535\t Weight: [1.96070464]\t Bias: [0.28279476]\t Cost: 0.008035818186707294\n",
            "Iteration: 536\t Weight: [1.96085959]\t Bias: [0.28167966]\t Cost: 0.00797257046142238\n",
            "Iteration: 537\t Weight: [1.96101393]\t Bias: [0.28056896]\t Cost: 0.007909820541670214\n",
            "Iteration: 538\t Weight: [1.96116765]\t Bias: [0.27946264]\t Cost: 0.007847564509359759\n",
            "Iteration: 539\t Weight: [1.96132078]\t Bias: [0.27836068]\t Cost: 0.007785798477238145\n",
            "Iteration: 540\t Weight: [1.96147329]\t Bias: [0.27726306]\t Cost: 0.007724518588647991\n",
            "Iteration: 541\t Weight: [1.96162521]\t Bias: [0.27616978]\t Cost: 0.007663721017286625\n",
            "Iteration: 542\t Weight: [1.96177653]\t Bias: [0.2750808]\t Cost: 0.007603401966967187\n",
            "Iteration: 543\t Weight: [1.96192725]\t Bias: [0.27399612]\t Cost: 0.007543557671381578\n",
            "Iteration: 544\t Weight: [1.96207737]\t Bias: [0.27291572]\t Cost: 0.007484184393865205\n",
            "Iteration: 545\t Weight: [1.96222691]\t Bias: [0.27183957]\t Cost: 0.007425278427163778\n",
            "Iteration: 546\t Weight: [1.96237585]\t Bias: [0.27076767]\t Cost: 0.007366836093201826\n",
            "Iteration: 547\t Weight: [1.96252421]\t Bias: [0.2697]\t Cost: 0.007308853742852919\n",
            "Iteration: 548\t Weight: [1.96267198]\t Bias: [0.26863653]\t Cost: 0.007251327755711915\n",
            "Iteration: 549\t Weight: [1.96281917]\t Bias: [0.26757726]\t Cost: 0.007194254539869002\n",
            "Iteration: 550\t Weight: [1.96296578]\t Bias: [0.26652217]\t Cost: 0.007137630531685282\n",
            "Iteration: 551\t Weight: [1.96311181]\t Bias: [0.26547124]\t Cost: 0.007081452195570102\n",
            "Iteration: 552\t Weight: [1.96325727]\t Bias: [0.26442445]\t Cost: 0.007025716023760632\n",
            "Iteration: 553\t Weight: [1.96340215]\t Bias: [0.26338178]\t Cost: 0.006970418536102739\n",
            "Iteration: 554\t Weight: [1.96354646]\t Bias: [0.26234323]\t Cost: 0.0069155562798334964\n",
            "Iteration: 555\t Weight: [1.9636902]\t Bias: [0.26130878]\t Cost: 0.0068611258293656855\n",
            "Iteration: 556\t Weight: [1.96383337]\t Bias: [0.2602784]\t Cost: 0.006807123786074189\n",
            "Iteration: 557\t Weight: [1.96397598]\t Bias: [0.25925209]\t Cost: 0.006753546778083378\n",
            "Iteration: 558\t Weight: [1.96411803]\t Bias: [0.25822982]\t Cost: 0.006700391460056766\n",
            "Iteration: 559\t Weight: [1.96425952]\t Bias: [0.25721159]\t Cost: 0.006647654512987898\n",
            "Iteration: 560\t Weight: [1.96440045]\t Bias: [0.25619737]\t Cost: 0.006595332643993642\n",
            "Iteration: 561\t Weight: [1.96454082]\t Bias: [0.25518714]\t Cost: 0.006543422586108073\n",
            "Iteration: 562\t Weight: [1.96468064]\t Bias: [0.25418091]\t Cost: 0.006491921098078613\n",
            "Iteration: 563\t Weight: [1.96481991]\t Bias: [0.25317864]\t Cost: 0.006440824964163884\n",
            "Iteration: 564\t Weight: [1.96495863]\t Bias: [0.25218032]\t Cost: 0.006390130993932491\n",
            "Iteration: 565\t Weight: [1.96509681]\t Bias: [0.25118594]\t Cost: 0.006339836022064217\n",
            "Iteration: 566\t Weight: [1.96523443]\t Bias: [0.25019548]\t Cost: 0.0062899369081521545\n",
            "Iteration: 567\t Weight: [1.96537152]\t Bias: [0.24920892]\t Cost: 0.0062404305365066914\n",
            "Iteration: 568\t Weight: [1.96550806]\t Bias: [0.24822626]\t Cost: 0.006191313815961042\n",
            "Iteration: 569\t Weight: [1.96564407]\t Bias: [0.24724746]\t Cost: 0.006142583679677887\n",
            "Iteration: 570\t Weight: [1.96577954]\t Bias: [0.24627253]\t Cost: 0.006094237084958506\n",
            "Iteration: 571\t Weight: [1.96591448]\t Bias: [0.24530145]\t Cost: 0.006046271013052039\n",
            "Iteration: 572\t Weight: [1.96604888]\t Bias: [0.24433419]\t Cost: 0.005998682468967698\n",
            "Iteration: 573\t Weight: [1.96618275]\t Bias: [0.24337075]\t Cost: 0.005951468481287375\n",
            "Iteration: 574\t Weight: [1.9663161]\t Bias: [0.2424111]\t Cost: 0.005904626101979988\n",
            "Iteration: 575\t Weight: [1.96644892]\t Bias: [0.24145524]\t Cost: 0.005858152406218012\n",
            "Iteration: 576\t Weight: [1.96658122]\t Bias: [0.24050315]\t Cost: 0.005812044492193918\n",
            "Iteration: 577\t Weight: [1.96671299]\t Bias: [0.23955481]\t Cost: 0.0057662994809399\n",
            "Iteration: 578\t Weight: [1.96684425]\t Bias: [0.23861022]\t Cost: 0.005720914516147587\n",
            "Iteration: 579\t Weight: [1.96697498]\t Bias: [0.23766934]\t Cost: 0.005675886763989864\n",
            "Iteration: 580\t Weight: [1.96710521]\t Bias: [0.23673218]\t Cost: 0.005631213412943762\n",
            "Iteration: 581\t Weight: [1.96723492]\t Bias: [0.23579871]\t Cost: 0.005586891673615274\n",
            "Iteration: 582\t Weight: [1.96736411]\t Bias: [0.23486893]\t Cost: 0.005542918778564709\n",
            "Iteration: 583\t Weight: [1.9674928]\t Bias: [0.23394281]\t Cost: 0.005499291982134253\n",
            "Iteration: 584\t Weight: [1.96762098]\t Bias: [0.23302034]\t Cost: 0.005456008560276506\n",
            "Iteration: 585\t Weight: [1.96774866]\t Bias: [0.23210151]\t Cost: 0.005413065810384072\n",
            "Iteration: 586\t Weight: [1.96787583]\t Bias: [0.2311863]\t Cost: 0.005370461051121301\n",
            "Iteration: 587\t Weight: [1.9680025]\t Bias: [0.2302747]\t Cost: 0.005328191622256361\n",
            "Iteration: 588\t Weight: [1.96812867]\t Bias: [0.22936669]\t Cost: 0.005286254884495489\n",
            "Iteration: 589\t Weight: [1.96825434]\t Bias: [0.22846227]\t Cost: 0.005244648219318063\n",
            "Iteration: 590\t Weight: [1.96837952]\t Bias: [0.22756141]\t Cost: 0.0052033690288132385\n",
            "Iteration: 591\t Weight: [1.9685042]\t Bias: [0.22666411]\t Cost: 0.0051624147355173984\n",
            "Iteration: 592\t Weight: [1.96862839]\t Bias: [0.22577034]\t Cost: 0.005121782782253593\n",
            "Iteration: 593\t Weight: [1.9687521]\t Bias: [0.2248801]\t Cost: 0.005081470631971599\n",
            "Iteration: 594\t Weight: [1.96887531]\t Bias: [0.22399336]\t Cost: 0.005041475767589807\n",
            "Iteration: 595\t Weight: [1.96899804]\t Bias: [0.22311013]\t Cost: 0.005001795691837664\n",
            "Iteration: 596\t Weight: [1.96912029]\t Bias: [0.22223037]\t Cost: 0.0049624279271\n",
            "Iteration: 597\t Weight: [1.96924205]\t Bias: [0.22135409]\t Cost: 0.0049233700152624075\n",
            "Iteration: 598\t Weight: [1.96936333]\t Bias: [0.22048126]\t Cost: 0.004884619517557477\n",
            "Iteration: 599\t Weight: [1.96948414]\t Bias: [0.21961187]\t Cost: 0.004846174014412733\n",
            "Iteration: 600\t Weight: [1.96960446]\t Bias: [0.21874591]\t Cost: 0.004808031105299385\n",
            "Iteration: 601\t Weight: [1.96972432]\t Bias: [0.21788336]\t Cost: 0.004770188408582774\n",
            "Iteration: 602\t Weight: [1.9698437]\t Bias: [0.21702422]\t Cost: 0.004732643561373274\n",
            "Iteration: 603\t Weight: [1.96996261]\t Bias: [0.21616846]\t Cost: 0.004695394219378921\n",
            "Iteration: 604\t Weight: [1.97008105]\t Bias: [0.21531608]\t Cost: 0.0046584380567590376\n",
            "Iteration: 605\t Weight: [1.97019903]\t Bias: [0.21446706]\t Cost: 0.004621772765979091\n",
            "Iteration: 606\t Weight: [1.97031653]\t Bias: [0.21362139]\t Cost: 0.004585396057666301\n",
            "Iteration: 607\t Weight: [1.97043358]\t Bias: [0.21277905]\t Cost: 0.004549305660467246\n",
            "Iteration: 608\t Weight: [1.97055017]\t Bias: [0.21194003]\t Cost: 0.004513499320905408\n",
            "Iteration: 609\t Weight: [1.97066629]\t Bias: [0.21110432]\t Cost: 0.004477974803240917\n",
            "Iteration: 610\t Weight: [1.97078196]\t Bias: [0.21027191]\t Cost: 0.004442729889330747\n",
            "Iteration: 611\t Weight: [1.97089717]\t Bias: [0.20944278]\t Cost: 0.004407762378490276\n",
            "Iteration: 612\t Weight: [1.97101192]\t Bias: [0.20861692]\t Cost: 0.004373070087355951\n",
            "Iteration: 613\t Weight: [1.97112623]\t Bias: [0.20779431]\t Cost: 0.004338650849748711\n",
            "Iteration: 614\t Weight: [1.97124008]\t Bias: [0.20697495]\t Cost: 0.004304502516539039\n",
            "Iteration: 615\t Weight: [1.97135349]\t Bias: [0.20615882]\t Cost: 0.004270622955512554\n",
            "Iteration: 616\t Weight: [1.97146644]\t Bias: [0.20534591]\t Cost: 0.004237010051237007\n",
            "Iteration: 617\t Weight: [1.97157895]\t Bias: [0.2045362]\t Cost: 0.004203661704930025\n",
            "Iteration: 618\t Weight: [1.97169102]\t Bias: [0.20372969]\t Cost: 0.004170575834328311\n",
            "Iteration: 619\t Weight: [1.97180265]\t Bias: [0.20292635]\t Cost: 0.004137750373557427\n",
            "Iteration: 620\t Weight: [1.97191383]\t Bias: [0.20212619]\t Cost: 0.004105183273002979\n",
            "Iteration: 621\t Weight: [1.97202458]\t Bias: [0.20132917]\t Cost: 0.004072872499182205\n",
            "Iteration: 622\t Weight: [1.97213489]\t Bias: [0.20053531]\t Cost: 0.00404081603461774\n",
            "Iteration: 623\t Weight: [1.97224477]\t Bias: [0.19974457]\t Cost: 0.004009011877710962\n",
            "Iteration: 624\t Weight: [1.97235421]\t Bias: [0.19895695]\t Cost: 0.003977458042617355\n",
            "Iteration: 625\t Weight: [1.97246322]\t Bias: [0.19817243]\t Cost: 0.003946152559122479\n",
            "Iteration: 626\t Weight: [1.9725718]\t Bias: [0.19739101]\t Cost: 0.003915093472518879\n",
            "Iteration: 627\t Weight: [1.97267996]\t Bias: [0.19661267]\t Cost: 0.0038842788434840544\n",
            "Iteration: 628\t Weight: [1.97278768]\t Bias: [0.1958374]\t Cost: 0.0038537067479594337\n",
            "Iteration: 629\t Weight: [1.97289499]\t Bias: [0.19506519]\t Cost: 0.0038233752770300495\n",
            "Iteration: 630\t Weight: [1.97300186]\t Bias: [0.19429602]\t Cost: 0.0037932825368056982\n",
            "Iteration: 631\t Weight: [1.97310832]\t Bias: [0.19352988]\t Cost: 0.0037634266483023366\n",
            "Iteration: 632\t Weight: [1.97321436]\t Bias: [0.19276677]\t Cost: 0.0037338057473247695\n",
            "Iteration: 633\t Weight: [1.97331998]\t Bias: [0.19200666]\t Cost: 0.003704417984350666\n",
            "Iteration: 634\t Weight: [1.97342518]\t Bias: [0.19124955]\t Cost: 0.003675261524414551\n",
            "Iteration: 635\t Weight: [1.97352997]\t Bias: [0.19049543]\t Cost: 0.003646334546993488\n",
            "Iteration: 636\t Weight: [1.97363435]\t Bias: [0.18974428]\t Cost: 0.003617635245893525\n",
            "Iteration: 637\t Weight: [1.97373831]\t Bias: [0.18899609]\t Cost: 0.0035891618291365255\n",
            "Iteration: 638\t Weight: [1.97384186]\t Bias: [0.18825086]\t Cost: 0.0035609125188487737\n",
            "Iteration: 639\t Weight: [1.97394501]\t Bias: [0.18750856]\t Cost: 0.0035328855511494897\n",
            "Iteration: 640\t Weight: [1.97404775]\t Bias: [0.18676918]\t Cost: 0.0035050791760411364\n",
            "Iteration: 641\t Weight: [1.97415008]\t Bias: [0.18603273]\t Cost: 0.003477491657299791\n",
            "Iteration: 642\t Weight: [1.97425201]\t Bias: [0.18529918]\t Cost: 0.003450121272366819\n",
            "Iteration: 643\t Weight: [1.97435354]\t Bias: [0.18456852]\t Cost: 0.0034229663122415047\n",
            "Iteration: 644\t Weight: [1.97445466]\t Bias: [0.18384074]\t Cost: 0.0033960250813741422\n",
            "Iteration: 645\t Weight: [1.97455539]\t Bias: [0.18311583]\t Cost: 0.0033692958975602414\n",
            "Iteration: 646\t Weight: [1.97465572]\t Bias: [0.18239378]\t Cost: 0.003342777091835516\n",
            "Iteration: 647\t Weight: [1.97475566]\t Bias: [0.18167457]\t Cost: 0.0033164670083716302\n",
            "Iteration: 648\t Weight: [1.9748552]\t Bias: [0.1809582]\t Cost: 0.003290364004372706\n",
            "Iteration: 649\t Weight: [1.97495435]\t Bias: [0.18024466]\t Cost: 0.0032644664499730525\n",
            "Iteration: 650\t Weight: [1.97505311]\t Bias: [0.17953393]\t Cost: 0.0032387727281351086\n",
            "Iteration: 651\t Weight: [1.97515148]\t Bias: [0.17882601]\t Cost: 0.003213281234548494\n",
            "Iteration: 652\t Weight: [1.97524946]\t Bias: [0.17812087]\t Cost: 0.003187990377530101\n",
            "Iteration: 653\t Weight: [1.97534706]\t Bias: [0.17741851]\t Cost: 0.003162898577924351\n",
            "Iteration: 654\t Weight: [1.97544427]\t Bias: [0.17671893]\t Cost: 0.003138004269004899\n",
            "Iteration: 655\t Weight: [1.97554109]\t Bias: [0.1760221]\t Cost: 0.003113305896376548\n",
            "Iteration: 656\t Weight: [1.97563754]\t Bias: [0.17532802]\t Cost: 0.0030888019178784243\n",
            "Iteration: 657\t Weight: [1.9757336]\t Bias: [0.17463668]\t Cost: 0.0030644908034874923\n",
            "Iteration: 658\t Weight: [1.97582929]\t Bias: [0.17394806]\t Cost: 0.0030403710352232736\n",
            "Iteration: 659\t Weight: [1.9759246]\t Bias: [0.17326216]\t Cost: 0.003016441107052617\n",
            "Iteration: 660\t Weight: [1.97601953]\t Bias: [0.17257897]\t Cost: 0.00299269952479625\n",
            "Iteration: 661\t Weight: [1.97611409]\t Bias: [0.17189846]\t Cost: 0.0029691448060349805\n",
            "Iteration: 662\t Weight: [1.97620827]\t Bias: [0.17122064]\t Cost: 0.0029457754800173847\n",
            "Iteration: 663\t Weight: [1.97630209]\t Bias: [0.1705455]\t Cost: 0.0029225900875679317\n",
            "Iteration: 664\t Weight: [1.97639553]\t Bias: [0.16987301]\t Cost: 0.002899587180995875\n",
            "Iteration: 665\t Weight: [1.97648861]\t Bias: [0.16920318]\t Cost: 0.002876765324004768\n",
            "Iteration: 666\t Weight: [1.97658131]\t Bias: [0.16853599]\t Cost: 0.0028541230916029844\n",
            "Iteration: 667\t Weight: [1.97667366]\t Bias: [0.16787143]\t Cost: 0.0028316590700145678\n",
            "Iteration: 668\t Weight: [1.97676564]\t Bias: [0.16720949]\t Cost: 0.0028093718565909078\n",
            "Iteration: 669\t Weight: [1.97685725]\t Bias: [0.16655016]\t Cost: 0.0027872600597234082\n",
            "Iteration: 670\t Weight: [1.97694851]\t Bias: [0.16589343]\t Cost: 0.0027653222987562677\n",
            "Iteration: 671\t Weight: [1.9770394]\t Bias: [0.16523929]\t Cost: 0.002743557203900694\n",
            "Iteration: 672\t Weight: [1.97712994]\t Bias: [0.16458773]\t Cost: 0.0027219634161489096\n",
            "Iteration: 673\t Weight: [1.97722012]\t Bias: [0.16393874]\t Cost: 0.0027005395871895666\n",
            "Iteration: 674\t Weight: [1.97730994]\t Bias: [0.1632923]\t Cost: 0.002679284379323608\n",
            "Iteration: 675\t Weight: [1.97739941]\t Bias: [0.16264842]\t Cost: 0.002658196465380537\n",
            "Iteration: 676\t Weight: [1.97748853]\t Bias: [0.16200707]\t Cost: 0.002637274528635632\n",
            "Iteration: 677\t Weight: [1.9775773]\t Bias: [0.16136826]\t Cost: 0.0026165172627278474\n",
            "Iteration: 678\t Weight: [1.97766571]\t Bias: [0.16073196]\t Cost: 0.0025959233715780626\n",
            "Iteration: 679\t Weight: [1.97775378]\t Bias: [0.16009817]\t Cost: 0.002575491569308318\n",
            "Iteration: 680\t Weight: [1.9778415]\t Bias: [0.15946688]\t Cost: 0.002555220580161464\n",
            "Iteration: 681\t Weight: [1.97792887]\t Bias: [0.15883808]\t Cost: 0.002535109138421317\n",
            "Iteration: 682\t Weight: [1.9780159]\t Bias: [0.15821176]\t Cost: 0.002515155988333918\n",
            "Iteration: 683\t Weight: [1.97810259]\t Bias: [0.15758791]\t Cost: 0.0024953598840290626\n",
            "Iteration: 684\t Weight: [1.97818893]\t Bias: [0.15696652]\t Cost: 0.0024757195894423477\n",
            "Iteration: 685\t Weight: [1.97827494]\t Bias: [0.15634758]\t Cost: 0.002456233878238189\n",
            "Iteration: 686\t Weight: [1.9783606]\t Bias: [0.15573108]\t Cost: 0.002436901533733024\n",
            "Iteration: 687\t Weight: [1.97844593]\t Bias: [0.15511701]\t Cost: 0.0024177213488195738\n",
            "Iteration: 688\t Weight: [1.97853092]\t Bias: [0.15450536]\t Cost: 0.0023986921258913104\n",
            "Iteration: 689\t Weight: [1.97861558]\t Bias: [0.15389613]\t Cost: 0.0023798126767678686\n",
            "Iteration: 690\t Weight: [1.9786999]\t Bias: [0.15328929]\t Cost: 0.0023610818226204727\n",
            "Iteration: 691\t Weight: [1.97878389]\t Bias: [0.15268485]\t Cost: 0.0023424983938989076\n",
            "Iteration: 692\t Weight: [1.97886754]\t Bias: [0.1520828]\t Cost: 0.0023240612302578853\n",
            "Iteration: 693\t Weight: [1.97895087]\t Bias: [0.15148311]\t Cost: 0.002305769180485062\n",
            "Iteration: 694\t Weight: [1.97903387]\t Bias: [0.15088579]\t Cost: 0.002287621102428868\n",
            "Iteration: 695\t Weight: [1.97911655]\t Bias: [0.15029083]\t Cost: 0.0022696158629273277\n",
            "Iteration: 696\t Weight: [1.97919889]\t Bias: [0.14969821]\t Cost: 0.002251752337737308\n",
            "Iteration: 697\t Weight: [1.97928091]\t Bias: [0.14910793]\t Cost: 0.002234029411464239\n",
            "Iteration: 698\t Weight: [1.97936261]\t Bias: [0.14851998]\t Cost: 0.0022164459774924967\n",
            "Iteration: 699\t Weight: [1.97944399]\t Bias: [0.14793435]\t Cost: 0.0021990009379164155\n",
            "Iteration: 700\t Weight: [1.97952504]\t Bias: [0.14735102]\t Cost: 0.0021816932034715974\n",
            "Iteration: 701\t Weight: [1.97960578]\t Bias: [0.14676999]\t Cost: 0.0021645216934668594\n",
            "Iteration: 702\t Weight: [1.9796862]\t Bias: [0.14619126]\t Cost: 0.0021474853357169804\n",
            "Iteration: 703\t Weight: [1.9797663]\t Bias: [0.14561481]\t Cost: 0.002130583066475544\n",
            "Iteration: 704\t Weight: [1.97984608]\t Bias: [0.14504063]\t Cost: 0.002113813830368657\n",
            "Iteration: 705\t Weight: [1.97992555]\t Bias: [0.14446871]\t Cost: 0.002097176580328843\n",
            "Iteration: 706\t Weight: [1.98000471]\t Bias: [0.14389905]\t Cost: 0.002080670277529959\n",
            "Iteration: 707\t Weight: [1.98008355]\t Bias: [0.14333164]\t Cost: 0.002064293891322112\n",
            "Iteration: 708\t Weight: [1.98016208]\t Bias: [0.14276646]\t Cost: 0.0020480463991673237\n",
            "Iteration: 709\t Weight: [1.98024031]\t Bias: [0.14220352]\t Cost: 0.002031926786575822\n",
            "Iteration: 710\t Weight: [1.98031822]\t Bias: [0.14164279]\t Cost: 0.002015934047042602\n",
            "Iteration: 711\t Weight: [1.98039583]\t Bias: [0.14108427]\t Cost: 0.002000067181984478\n",
            "Iteration: 712\t Weight: [1.98047313]\t Bias: [0.14052796]\t Cost: 0.0019843252006780158\n",
            "Iteration: 713\t Weight: [1.98055013]\t Bias: [0.13997384]\t Cost: 0.001968707120197295\n",
            "Iteration: 714\t Weight: [1.98062682]\t Bias: [0.1394219]\t Cost: 0.001953211965352849\n",
            "Iteration: 715\t Weight: [1.98070321]\t Bias: [0.13887214]\t Cost: 0.0019378387686306714\n",
            "Iteration: 716\t Weight: [1.9807793]\t Bias: [0.13832455]\t Cost: 0.0019225865701317844\n",
            "Iteration: 717\t Weight: [1.98085509]\t Bias: [0.13777911]\t Cost: 0.0019074544175122369\n",
            "Iteration: 718\t Weight: [1.98093058]\t Bias: [0.13723583]\t Cost: 0.001892441365923793\n",
            "Iteration: 719\t Weight: [1.98100578]\t Bias: [0.13669469]\t Cost: 0.0018775464779548733\n",
            "Iteration: 720\t Weight: [1.98108067]\t Bias: [0.13615569]\t Cost: 0.0018627688235719104\n",
            "Iteration: 721\t Weight: [1.98115528]\t Bias: [0.13561881]\t Cost: 0.0018481074800614946\n",
            "Iteration: 722\t Weight: [1.98122958]\t Bias: [0.13508404]\t Cost: 0.001833561531972546\n",
            "Iteration: 723\t Weight: [1.9813036]\t Bias: [0.13455139]\t Cost: 0.0018191300710593199\n",
            "Iteration: 724\t Weight: [1.98137732]\t Bias: [0.13402083]\t Cost: 0.0018048121962246167\n",
            "Iteration: 725\t Weight: [1.98145075]\t Bias: [0.13349237]\t Cost: 0.0017906070134634526\n",
            "Iteration: 726\t Weight: [1.98152389]\t Bias: [0.13296599]\t Cost: 0.001776513635807362\n",
            "Iteration: 727\t Weight: [1.98159675]\t Bias: [0.13244169]\t Cost: 0.0017625311832690246\n",
            "Iteration: 728\t Weight: [1.98166931]\t Bias: [0.13191945]\t Cost: 0.00174865878278713\n",
            "Iteration: 729\t Weight: [1.98174159]\t Bias: [0.13139928]\t Cost: 0.0017348955681721562\n",
            "Iteration: 730\t Weight: [1.98181359]\t Bias: [0.13088115]\t Cost: 0.0017212406800519399\n",
            "Iteration: 731\t Weight: [1.9818853]\t Bias: [0.13036507]\t Cost: 0.0017076932658183527\n",
            "Iteration: 732\t Weight: [1.98195673]\t Bias: [0.12985102]\t Cost: 0.0016942524795738499\n",
            "Iteration: 733\t Weight: [1.98202788]\t Bias: [0.129339]\t Cost: 0.0016809174820786284\n",
            "Iteration: 734\t Weight: [1.98209874]\t Bias: [0.128829]\t Cost: 0.0016676874406985646\n",
            "Iteration: 735\t Weight: [1.98216933]\t Bias: [0.12832101]\t Cost: 0.0016545615293526465\n",
            "Iteration: 736\t Weight: [1.98223964]\t Bias: [0.12781502]\t Cost: 0.0016415389284619886\n",
            "Iteration: 737\t Weight: [1.98230967]\t Bias: [0.12731103]\t Cost: 0.0016286188248982247\n",
            "Iteration: 738\t Weight: [1.98237943]\t Bias: [0.12680903]\t Cost: 0.0016158004119329581\n",
            "Iteration: 739\t Weight: [1.98244891]\t Bias: [0.126309]\t Cost: 0.0016030828891873288\n",
            "Iteration: 740\t Weight: [1.98251811]\t Bias: [0.12581095]\t Cost: 0.001590465462582035\n",
            "Iteration: 741\t Weight: [1.98258705]\t Bias: [0.12531486]\t Cost: 0.0015779473442877347\n",
            "Iteration: 742\t Weight: [1.98265571]\t Bias: [0.12482072]\t Cost: 0.0015655277526759339\n",
            "Iteration: 743\t Weight: [1.9827241]\t Bias: [0.12432854]\t Cost: 0.001553205912270069\n",
            "Iteration: 744\t Weight: [1.98279222]\t Bias: [0.12383829]\t Cost: 0.0015409810536971356\n",
            "Iteration: 745\t Weight: [1.98286007]\t Bias: [0.12334998]\t Cost: 0.0015288524136397395\n",
            "Iteration: 746\t Weight: [1.98292766]\t Bias: [0.1228636]\t Cost: 0.0015168192347881793\n",
            "Iteration: 747\t Weight: [1.98299498]\t Bias: [0.12237913]\t Cost: 0.0015048807657935014\n",
            "Iteration: 748\t Weight: [1.98306203]\t Bias: [0.12189657]\t Cost: 0.001493036261220374\n",
            "Iteration: 749\t Weight: [1.98312882]\t Bias: [0.12141591]\t Cost: 0.0014812849815004855\n",
            "Iteration: 750\t Weight: [1.98319534]\t Bias: [0.12093716]\t Cost: 0.001469626192886581\n",
            "Iteration: 751\t Weight: [1.98326161]\t Bias: [0.12046028]\t Cost: 0.0014580591674064692\n",
            "Iteration: 752\t Weight: [1.98332761]\t Bias: [0.11998529]\t Cost: 0.001446583182817621\n",
            "Iteration: 753\t Weight: [1.98339335]\t Bias: [0.11951217]\t Cost: 0.0014351975225621566\n",
            "Iteration: 754\t Weight: [1.98345883]\t Bias: [0.11904092]\t Cost: 0.0014239014757219297\n",
            "Iteration: 755\t Weight: [1.98352406]\t Bias: [0.11857153]\t Cost: 0.0014126943369743002\n",
            "Iteration: 756\t Weight: [1.98358902]\t Bias: [0.11810398]\t Cost: 0.0014015754065479736\n",
            "Iteration: 757\t Weight: [1.98365373]\t Bias: [0.11763828]\t Cost: 0.0013905439901794412\n",
            "Iteration: 758\t Weight: [1.98371819]\t Bias: [0.11717442]\t Cost: 0.0013795993990694797\n",
            "Iteration: 759\t Weight: [1.98378239]\t Bias: [0.11671238]\t Cost: 0.001368740949840279\n",
            "Iteration: 760\t Weight: [1.98384634]\t Bias: [0.11625217]\t Cost: 0.001357967964492615\n",
            "Iteration: 761\t Weight: [1.98391004]\t Bias: [0.11579377]\t Cost: 0.0013472797703637414\n",
            "Iteration: 762\t Weight: [1.98397348]\t Bias: [0.11533718]\t Cost: 0.001336675700085124\n",
            "Iteration: 763\t Weight: [1.98403668]\t Bias: [0.11488239]\t Cost: 0.0013261550915410162\n",
            "Iteration: 764\t Weight: [1.98409962]\t Bias: [0.11442939]\t Cost: 0.001315717287826907\n",
            "Iteration: 765\t Weight: [1.98416232]\t Bias: [0.11397818]\t Cost: 0.001305361637208688\n",
            "Iteration: 766\t Weight: [1.98422477]\t Bias: [0.11352875]\t Cost: 0.0012950874930818164\n",
            "Iteration: 767\t Weight: [1.98428697]\t Bias: [0.11308109]\t Cost: 0.0012848942139310005\n",
            "Iteration: 768\t Weight: [1.98434893]\t Bias: [0.1126352]\t Cost: 0.0012747811632901208\n",
            "Iteration: 769\t Weight: [1.98441065]\t Bias: [0.11219106]\t Cost: 0.0012647477097026002\n",
            "Iteration: 770\t Weight: [1.98447212]\t Bias: [0.11174868]\t Cost: 0.0012547932266817842\n",
            "Iteration: 771\t Weight: [1.98453335]\t Bias: [0.11130804]\t Cost: 0.001244917092671954\n",
            "Iteration: 772\t Weight: [1.98459433]\t Bias: [0.11086913]\t Cost: 0.0012351186910094848\n",
            "Iteration: 773\t Weight: [1.98465508]\t Bias: [0.11043196]\t Cost: 0.0012253974098843745\n",
            "Iteration: 774\t Weight: [1.98471559]\t Bias: [0.10999651]\t Cost: 0.001215752642301972\n",
            "Iteration: 775\t Weight: [1.98477585]\t Bias: [0.10956278]\t Cost: 0.0012061837860451409\n",
            "Iteration: 776\t Weight: [1.98483589]\t Bias: [0.10913076]\t Cost: 0.0011966902436365734\n",
            "Iteration: 777\t Weight: [1.98489568]\t Bias: [0.10870044]\t Cost: 0.0011872714223016563\n",
            "Iteration: 778\t Weight: [1.98495524]\t Bias: [0.10827182]\t Cost: 0.0011779267339311872\n",
            "Iteration: 779\t Weight: [1.98501456]\t Bias: [0.10784489]\t Cost: 0.0011686555950449682\n",
            "Iteration: 780\t Weight: [1.98507365]\t Bias: [0.10741964]\t Cost: 0.0011594574267550892\n",
            "Iteration: 781\t Weight: [1.98513251]\t Bias: [0.10699607]\t Cost: 0.0011503316547299873\n",
            "Iteration: 782\t Weight: [1.98519113]\t Bias: [0.10657417]\t Cost: 0.001141277709158502\n",
            "Iteration: 783\t Weight: [1.98524953]\t Bias: [0.10615394]\t Cost: 0.0011322950247142642\n",
            "Iteration: 784\t Weight: [1.98530769]\t Bias: [0.10573536]\t Cost: 0.0011233830405203995\n",
            "Iteration: 785\t Weight: [1.98536562]\t Bias: [0.10531843]\t Cost: 0.001114541200114631\n",
            "Iteration: 786\t Weight: [1.98542333]\t Bias: [0.10490314]\t Cost: 0.0011057689514144097\n",
            "Iteration: 787\t Weight: [1.98548081]\t Bias: [0.1044895]\t Cost: 0.0010970657466824543\n",
            "Iteration: 788\t Weight: [1.98553806]\t Bias: [0.10407748]\t Cost: 0.001088431042492601\n",
            "Iteration: 789\t Weight: [1.98559508]\t Bias: [0.10366709]\t Cost: 0.0010798642996958457\n",
            "Iteration: 790\t Weight: [1.98565188]\t Bias: [0.10325831]\t Cost: 0.0010713649833866128\n",
            "Iteration: 791\t Weight: [1.98570846]\t Bias: [0.10285115]\t Cost: 0.0010629325628695291\n",
            "Iteration: 792\t Weight: [1.98576481]\t Bias: [0.1024456]\t Cost: 0.0010545665116261066\n",
            "Iteration: 793\t Weight: [1.98582094]\t Bias: [0.10204164]\t Cost: 0.001046266307281966\n",
            "Iteration: 794\t Weight: [1.98587685]\t Bias: [0.10163928]\t Cost: 0.0010380314315742043\n",
            "Iteration: 795\t Weight: [1.98593254]\t Bias: [0.1012385]\t Cost: 0.0010298613703189662\n",
            "Iteration: 796\t Weight: [1.98598801]\t Bias: [0.1008393]\t Cost: 0.0010217556133794642\n",
            "Iteration: 797\t Weight: [1.98604327]\t Bias: [0.10044168]\t Cost: 0.0010137136546340352\n",
            "Iteration: 798\t Weight: [1.9860983]\t Bias: [0.10004562]\t Cost: 0.0010057349919445286\n",
            "Iteration: 799\t Weight: [1.98615312]\t Bias: [0.09965113]\t Cost: 0.0009978191271250328\n",
            "Iteration: 800\t Weight: [1.98620772]\t Bias: [0.09925819]\t Cost: 0.0009899655659107336\n",
            "Iteration: 801\t Weight: [1.9862621]\t Bias: [0.0988668]\t Cost: 0.0009821738179269608\n",
            "Iteration: 802\t Weight: [1.98631627]\t Bias: [0.09847696]\t Cost: 0.0009744433966586874\n",
            "Iteration: 803\t Weight: [1.98637023]\t Bias: [0.09808865]\t Cost: 0.0009667738194201857\n",
            "Iteration: 804\t Weight: [1.98642397]\t Bias: [0.09770187]\t Cost: 0.0009591646073247225\n",
            "Iteration: 805\t Weight: [1.9864775]\t Bias: [0.09731662]\t Cost: 0.0009516152852547596\n",
            "Iteration: 806\t Weight: [1.98653082]\t Bias: [0.09693289]\t Cost: 0.0009441253818323046\n",
            "Iteration: 807\t Weight: [1.98658394]\t Bias: [0.09655067]\t Cost: 0.0009366944293894739\n",
            "Iteration: 808\t Weight: [1.98663684]\t Bias: [0.09616995]\t Cost: 0.0009293219639392532\n",
            "Iteration: 809\t Weight: [1.98668953]\t Bias: [0.09579074]\t Cost: 0.0009220075251464553\n",
            "Iteration: 810\t Weight: [1.98674201]\t Bias: [0.09541303]\t Cost: 0.0009147506562992274\n",
            "Iteration: 811\t Weight: [1.98679429]\t Bias: [0.0950368]\t Cost: 0.0009075509042802533\n",
            "Iteration: 812\t Weight: [1.98684636]\t Bias: [0.09466206]\t Cost: 0.0009004078195386388\n",
            "Iteration: 813\t Weight: [1.98689823]\t Bias: [0.09428879]\t Cost: 0.0008933209560617365\n",
            "Iteration: 814\t Weight: [1.98694989]\t Bias: [0.093917]\t Cost: 0.0008862898713473159\n",
            "Iteration: 815\t Weight: [1.98700135]\t Bias: [0.09354667]\t Cost: 0.0008793141263760692\n",
            "Iteration: 816\t Weight: [1.98705261]\t Bias: [0.0931778]\t Cost: 0.0008723932855840126\n",
            "Iteration: 817\t Weight: [1.98710366]\t Bias: [0.09281039]\t Cost: 0.0008655269168353543\n",
            "Iteration: 818\t Weight: [1.98715451]\t Bias: [0.09244443]\t Cost: 0.000858714591395584\n",
            "Iteration: 819\t Weight: [1.98720516]\t Bias: [0.0920799]\t Cost: 0.0008519558839046027\n",
            "Iteration: 820\t Weight: [1.98725562]\t Bias: [0.09171682]\t Cost: 0.0008452503723501794\n",
            "Iteration: 821\t Weight: [1.98730587]\t Bias: [0.09135517]\t Cost: 0.0008385976380417159\n",
            "Iteration: 822\t Weight: [1.98735592]\t Bias: [0.09099494]\t Cost: 0.0008319972655839003\n",
            "Iteration: 823\t Weight: [1.98740578]\t Bias: [0.09063614]\t Cost: 0.000825448842850985\n",
            "Iteration: 824\t Weight: [1.98745544]\t Bias: [0.09027875]\t Cost: 0.0008189519609608766\n",
            "Iteration: 825\t Weight: [1.98750491]\t Bias: [0.08992276]\t Cost: 0.0008125062142497042\n",
            "Iteration: 826\t Weight: [1.98755418]\t Bias: [0.08956819]\t Cost: 0.000806111200246517\n",
            "Iteration: 827\t Weight: [1.98760325]\t Bias: [0.08921501]\t Cost: 0.000799766519648017\n",
            "Iteration: 828\t Weight: [1.98765213]\t Bias: [0.08886322]\t Cost: 0.0007934717762937786\n",
            "Iteration: 829\t Weight: [1.98770082]\t Bias: [0.08851282]\t Cost: 0.0007872265771413764\n",
            "Iteration: 830\t Weight: [1.98774932]\t Bias: [0.0881638]\t Cost: 0.0007810305322420045\n",
            "Iteration: 831\t Weight: [1.98779763]\t Bias: [0.08781616]\t Cost: 0.0007748832547159822\n",
            "Iteration: 832\t Weight: [1.98784574]\t Bias: [0.08746989]\t Cost: 0.0007687843607286389\n",
            "Iteration: 833\t Weight: [1.98789367]\t Bias: [0.08712498]\t Cost: 0.0007627334694664248\n",
            "Iteration: 834\t Weight: [1.98794141]\t Bias: [0.08678144]\t Cost: 0.0007567302031130037\n",
            "Iteration: 835\t Weight: [1.98798895]\t Bias: [0.08643925]\t Cost: 0.0007507741868257772\n",
            "Iteration: 836\t Weight: [1.98803632]\t Bias: [0.0860984]\t Cost: 0.0007448650487123895\n",
            "Iteration: 837\t Weight: [1.98808349]\t Bias: [0.08575891]\t Cost: 0.0007390024198075601\n",
            "Iteration: 838\t Weight: [1.98813048]\t Bias: [0.08542075]\t Cost: 0.000733185934050059\n",
            "Iteration: 839\t Weight: [1.98817728]\t Bias: [0.08508392]\t Cost: 0.0007274152282597824\n",
            "Iteration: 840\t Weight: [1.9882239]\t Bias: [0.08474842]\t Cost: 0.0007216899421151712\n",
            "Iteration: 841\t Weight: [1.98827033]\t Bias: [0.08441425]\t Cost: 0.0007160097181306176\n",
            "Iteration: 842\t Weight: [1.98831659]\t Bias: [0.08408139]\t Cost: 0.0007103742016341453\n",
            "Iteration: 843\t Weight: [1.98836266]\t Bias: [0.08374985]\t Cost: 0.0007047830407454181\n",
            "Iteration: 844\t Weight: [1.98840854]\t Bias: [0.08341961]\t Cost: 0.0006992358863535685\n",
            "Iteration: 845\t Weight: [1.98845425]\t Bias: [0.08309068]\t Cost: 0.0006937323920955011\n",
            "Iteration: 846\t Weight: [1.98849978]\t Bias: [0.08276304]\t Cost: 0.0006882722143342386\n",
            "Iteration: 847\t Weight: [1.98854512]\t Bias: [0.08243669]\t Cost: 0.0006828550121375267\n",
            "Iteration: 848\t Weight: [1.98859029]\t Bias: [0.08211163]\t Cost: 0.000677480447256434\n",
            "Iteration: 849\t Weight: [1.98863528]\t Bias: [0.08178786]\t Cost: 0.000672148184104334\n",
            "Iteration: 850\t Weight: [1.98868009]\t Bias: [0.08146535]\t Cost: 0.0006668578897358869\n",
            "Iteration: 851\t Weight: [1.98872473]\t Bias: [0.08114413]\t Cost: 0.0006616092338262891\n",
            "Iteration: 852\t Weight: [1.98876919]\t Bias: [0.08082416]\t Cost: 0.0006564018886506334\n",
            "Iteration: 853\t Weight: [1.98881347]\t Bias: [0.08050546]\t Cost: 0.000651235529063435\n",
            "Iteration: 854\t Weight: [1.98885758]\t Bias: [0.08018802]\t Cost: 0.0006461098324783407\n",
            "Iteration: 855\t Weight: [1.98890152]\t Bias: [0.07987183]\t Cost: 0.0006410244788480036\n",
            "Iteration: 856\t Weight: [1.98894528]\t Bias: [0.07955688]\t Cost: 0.0006359791506440745\n",
            "Iteration: 857\t Weight: [1.98898887]\t Bias: [0.07924318]\t Cost: 0.0006309735328373765\n",
            "Iteration: 858\t Weight: [1.98903229]\t Bias: [0.07893071]\t Cost: 0.0006260073128782217\n",
            "Iteration: 859\t Weight: [1.98907554]\t Bias: [0.07861948]\t Cost: 0.0006210801806769559\n",
            "Iteration: 860\t Weight: [1.98911862]\t Bias: [0.07830947]\t Cost: 0.0006161918285845166\n",
            "Iteration: 861\t Weight: [1.98916152]\t Bias: [0.07800068]\t Cost: 0.0006113419513733069\n",
            "Iteration: 862\t Weight: [1.98920426]\t Bias: [0.07769312]\t Cost: 0.000606530246218068\n",
            "Iteration: 863\t Weight: [1.98924683]\t Bias: [0.07738676]\t Cost: 0.0006017564126769898\n",
            "Iteration: 864\t Weight: [1.98928923]\t Bias: [0.07708161]\t Cost: 0.0005970201526729158\n",
            "Iteration: 865\t Weight: [1.98933146]\t Bias: [0.07677767]\t Cost: 0.0005923211704749192\n",
            "Iteration: 866\t Weight: [1.98937353]\t Bias: [0.07647493]\t Cost: 0.0005876591726795219\n",
            "Iteration: 867\t Weight: [1.98941543]\t Bias: [0.07617337]\t Cost: 0.0005830338681926333\n",
            "Iteration: 868\t Weight: [1.98945717]\t Bias: [0.07587301]\t Cost: 0.0005784449682112608\n",
            "Iteration: 869\t Weight: [1.98949874]\t Bias: [0.07557384]\t Cost: 0.000573892186205531\n",
            "Iteration: 870\t Weight: [1.98954015]\t Bias: [0.07527584]\t Cost: 0.0005693752379006867\n",
            "Iteration: 871\t Weight: [1.98958139]\t Bias: [0.07497901]\t Cost: 0.0005648938412595635\n",
            "Iteration: 872\t Weight: [1.98962248]\t Bias: [0.07468336]\t Cost: 0.0005604477164646525\n",
            "Iteration: 873\t Weight: [1.9896634]\t Bias: [0.07438887]\t Cost: 0.0005560365859009961\n",
            "Iteration: 874\t Weight: [1.98970416]\t Bias: [0.07409555]\t Cost: 0.0005516601741385222\n",
            "Iteration: 875\t Weight: [1.98974475]\t Bias: [0.07380338]\t Cost: 0.0005473182079150533\n",
            "Iteration: 876\t Weight: [1.98978519]\t Bias: [0.07351236]\t Cost: 0.0005430104161191942\n",
            "Iteration: 877\t Weight: [1.98982547]\t Bias: [0.07322249]\t Cost: 0.0005387365297733976\n",
            "Iteration: 878\t Weight: [1.98986559]\t Bias: [0.07293377]\t Cost: 0.0005344962820171127\n",
            "Iteration: 879\t Weight: [1.98990555]\t Bias: [0.07264618]\t Cost: 0.0005302894080902277\n",
            "Iteration: 880\t Weight: [1.98994535]\t Bias: [0.07235973]\t Cost: 0.0005261156453164706\n",
            "Iteration: 881\t Weight: [1.989985]\t Bias: [0.0720744]\t Cost: 0.0005219747330870089\n",
            "Iteration: 882\t Weight: [1.99002449]\t Bias: [0.0717902]\t Cost: 0.000517866412844199\n",
            "Iteration: 883\t Weight: [1.99006383]\t Bias: [0.07150712]\t Cost: 0.0005137904280654429\n",
            "Iteration: 884\t Weight: [1.99010301]\t Bias: [0.07122516]\t Cost: 0.0005097465242471607\n",
            "Iteration: 885\t Weight: [1.99014203]\t Bias: [0.07094431]\t Cost: 0.0005057344488888599\n",
            "Iteration: 886\t Weight: [1.9901809]\t Bias: [0.07066457]\t Cost: 0.0005017539514775035\n",
            "Iteration: 887\t Weight: [1.99021962]\t Bias: [0.07038593]\t Cost: 0.0004978047834716691\n",
            "Iteration: 888\t Weight: [1.99025819]\t Bias: [0.07010839]\t Cost: 0.0004938866982861829\n",
            "Iteration: 889\t Weight: [1.9902966]\t Bias: [0.06983194]\t Cost: 0.0004899994512766912\n",
            "Iteration: 890\t Weight: [1.99033486]\t Bias: [0.06955658]\t Cost: 0.0004861427997243488\n",
            "Iteration: 891\t Weight: [1.99037297]\t Bias: [0.06928231]\t Cost: 0.00048231650282068986\n",
            "Iteration: 892\t Weight: [1.99041093]\t Bias: [0.06900912]\t Cost: 0.0004785203216525651\n",
            "Iteration: 893\t Weight: [1.99044874]\t Bias: [0.06873701]\t Cost: 0.00047475401918728666\n",
            "Iteration: 894\t Weight: [1.99048641]\t Bias: [0.06846597]\t Cost: 0.00047101736025775967\n",
            "Iteration: 895\t Weight: [1.99052392]\t Bias: [0.068196]\t Cost: 0.00046731011154781924\n",
            "Iteration: 896\t Weight: [1.99056128]\t Bias: [0.06792709]\t Cost: 0.00046363204157767713\n",
            "Iteration: 897\t Weight: [1.9905985]\t Bias: [0.06765925]\t Cost: 0.00045998292068945876\n",
            "Iteration: 898\t Weight: [1.99063557]\t Bias: [0.06739246]\t Cost: 0.00045636252103288446\n",
            "Iteration: 899\t Weight: [1.9906725]\t Bias: [0.06712672]\t Cost: 0.0004527706165509731\n",
            "Iteration: 900\t Weight: [1.99070928]\t Bias: [0.06686203]\t Cost: 0.00044920698296602293\n",
            "Iteration: 901\t Weight: [1.99074591]\t Bias: [0.06659838]\t Cost: 0.0004456713977655358\n",
            "Iteration: 902\t Weight: [1.9907824]\t Bias: [0.06633578]\t Cost: 0.0004421636401883554\n",
            "Iteration: 903\t Weight: [1.99081875]\t Bias: [0.06607421]\t Cost: 0.00043868349121088955\n",
            "Iteration: 904\t Weight: [1.99085495]\t Bias: [0.06581367]\t Cost: 0.000435230733533377\n",
            "Iteration: 905\t Weight: [1.99089101]\t Bias: [0.06555415]\t Cost: 0.0004318051515664413\n",
            "Iteration: 906\t Weight: [1.99092693]\t Bias: [0.06529566]\t Cost: 0.00042840653141746547\n",
            "Iteration: 907\t Weight: [1.99096271]\t Bias: [0.0650382]\t Cost: 0.00042503466087736425\n",
            "Iteration: 908\t Weight: [1.99099834]\t Bias: [0.06478174]\t Cost: 0.0004216893294072982\n",
            "Iteration: 909\t Weight: [1.99103384]\t Bias: [0.0645263]\t Cost: 0.00041837032812550235\n",
            "Iteration: 910\t Weight: [1.99106919]\t Bias: [0.06427186]\t Cost: 0.0004150774497942813\n",
            "Iteration: 911\t Weight: [1.99110441]\t Bias: [0.06401843]\t Cost: 0.0004118104888070395\n",
            "Iteration: 912\t Weight: [1.99113948]\t Bias: [0.06376599]\t Cost: 0.0004085692411754432\n",
            "Iteration: 913\t Weight: [1.99117442]\t Bias: [0.06351456]\t Cost: 0.0004053535045167208\n",
            "Iteration: 914\t Weight: [1.99120922]\t Bias: [0.06326411]\t Cost: 0.000402163078041021\n",
            "Iteration: 915\t Weight: [1.99124389]\t Bias: [0.06301465]\t Cost: 0.00039899776253876613\n",
            "Iteration: 916\t Weight: [1.99127841]\t Bias: [0.06276618]\t Cost: 0.00039585736036837425\n",
            "Iteration: 917\t Weight: [1.9913128]\t Bias: [0.06251868]\t Cost: 0.00039274167544384647\n",
            "Iteration: 918\t Weight: [1.99134706]\t Bias: [0.06227216]\t Cost: 0.000389650513222487\n",
            "Iteration: 919\t Weight: [1.99138118]\t Bias: [0.06202661]\t Cost: 0.0003865836806928406\n",
            "Iteration: 920\t Weight: [1.99141516]\t Bias: [0.06178203]\t Cost: 0.0003835409863625178\n",
            "Iteration: 921\t Weight: [1.99144901]\t Bias: [0.06153842]\t Cost: 0.0003805222402464004\n",
            "Iteration: 922\t Weight: [1.99148273]\t Bias: [0.06129576]\t Cost: 0.0003775272538546409\n",
            "Iteration: 923\t Weight: [1.99151632]\t Bias: [0.06105407]\t Cost: 0.0003745558401809202\n",
            "Iteration: 924\t Weight: [1.99154977]\t Bias: [0.06081332]\t Cost: 0.000371607813690885\n",
            "Iteration: 925\t Weight: [1.99158309]\t Bias: [0.06057353]\t Cost: 0.00036868299031036903\n",
            "Iteration: 926\t Weight: [1.99161628]\t Bias: [0.06033468]\t Cost: 0.000365781187414057\n",
            "Iteration: 927\t Weight: [1.99164934]\t Bias: [0.06009677]\t Cost: 0.0003629022238140374\n",
            "Iteration: 928\t Weight: [1.99168226]\t Bias: [0.0598598]\t Cost: 0.00036004591974844117\n",
            "Iteration: 929\t Weight: [1.99171506]\t Bias: [0.05962376]\t Cost: 0.00035721209687028277\n",
            "Iteration: 930\t Weight: [1.99174773]\t Bias: [0.05938866]\t Cost: 0.00035440057823628947\n",
            "Iteration: 931\t Weight: [1.99178027]\t Bias: [0.05915448]\t Cost: 0.00035161118829586755\n",
            "Iteration: 932\t Weight: [1.99181268]\t Bias: [0.05892123]\t Cost: 0.0003488437528801087\n",
            "Iteration: 933\t Weight: [1.99184497]\t Bias: [0.05868889]\t Cost: 0.000346098099190974\n",
            "Iteration: 934\t Weight: [1.99187712]\t Bias: [0.05845747]\t Cost: 0.0003433740557904587\n",
            "Iteration: 935\t Weight: [1.99190915]\t Bias: [0.05822697]\t Cost: 0.00034067145258989006\n",
            "Iteration: 936\t Weight: [1.99194106]\t Bias: [0.05799737]\t Cost: 0.00033799012083931504\n",
            "Iteration: 937\t Weight: [1.99197283]\t Bias: [0.05776868]\t Cost: 0.0003353298931169877\n",
            "Iteration: 938\t Weight: [1.99200449]\t Bias: [0.05754089]\t Cost: 0.0003326906033188759\n",
            "Iteration: 939\t Weight: [1.99203601]\t Bias: [0.057314]\t Cost: 0.0003300720866482933\n",
            "Iteration: 940\t Weight: [1.99206742]\t Bias: [0.057088]\t Cost: 0.00032747417960567594\n",
            "Iteration: 941\t Weight: [1.99209869]\t Bias: [0.0568629]\t Cost: 0.00032489671997823944\n",
            "Iteration: 942\t Weight: [1.99212985]\t Bias: [0.05663868]\t Cost: 0.000322339546830014\n",
            "Iteration: 943\t Weight: [1.99216088]\t Bias: [0.05641534]\t Cost: 0.00031980250049164243\n",
            "Iteration: 944\t Weight: [1.99219179]\t Bias: [0.05619289]\t Cost: 0.00031728542255052874\n",
            "Iteration: 945\t Weight: [1.99222258]\t Bias: [0.05597131]\t Cost: 0.0003147881558408799\n",
            "Iteration: 946\t Weight: [1.99225325]\t Bias: [0.05575061]\t Cost: 0.00031231054443394226\n",
            "Iteration: 947\t Weight: [1.9922838]\t Bias: [0.05553078]\t Cost: 0.00030985243362816663\n",
            "Iteration: 948\t Weight: [1.99231422]\t Bias: [0.05531181]\t Cost: 0.0003074136699396793\n",
            "Iteration: 949\t Weight: [1.99234453]\t Bias: [0.05509371]\t Cost: 0.00030499410109262955\n",
            "Iteration: 950\t Weight: [1.99237472]\t Bias: [0.05487647]\t Cost: 0.00030259357600964697\n",
            "Iteration: 951\t Weight: [1.99240478]\t Bias: [0.05466008]\t Cost: 0.00030021194480250407\n",
            "Iteration: 952\t Weight: [1.99243473]\t Bias: [0.05444455]\t Cost: 0.0002978490587626551\n",
            "Iteration: 953\t Weight: [1.99246456]\t Bias: [0.05422987]\t Cost: 0.0002955047703520345\n",
            "Iteration: 954\t Weight: [1.99249428]\t Bias: [0.05401603]\t Cost: 0.0002931789331937675\n",
            "Iteration: 955\t Weight: [1.99252387]\t Bias: [0.05380304]\t Cost: 0.0002908714020631418\n",
            "Iteration: 956\t Weight: [1.99255335]\t Bias: [0.05359089]\t Cost: 0.00028858203287837766\n",
            "Iteration: 957\t Weight: [1.99258272]\t Bias: [0.05337957]\t Cost: 0.0002863106826918098\n",
            "Iteration: 958\t Weight: [1.99261196]\t Bias: [0.05316909]\t Cost: 0.0002840572096808227\n",
            "Iteration: 959\t Weight: [1.99264109]\t Bias: [0.05295944]\t Cost: 0.00028182147313904137\n",
            "Iteration: 960\t Weight: [1.99267011]\t Bias: [0.05275061]\t Cost: 0.000279603333467591\n",
            "Iteration: 961\t Weight: [1.99269901]\t Bias: [0.05254261]\t Cost: 0.0002774026521663113\n",
            "Iteration: 962\t Weight: [1.9927278]\t Bias: [0.05233542]\t Cost: 0.000275219291825165\n",
            "Iteration: 963\t Weight: [1.99275648]\t Bias: [0.05212906]\t Cost: 0.00027305311611561267\n",
            "Iteration: 964\t Weight: [1.99278504]\t Bias: [0.05192351]\t Cost: 0.0002709039897821146\n",
            "Iteration: 965\t Weight: [1.99281349]\t Bias: [0.05171876]\t Cost: 0.0002687717786336897\n",
            "Iteration: 966\t Weight: [1.99284183]\t Bias: [0.05151483]\t Cost: 0.0002666563495355792\n",
            "Iteration: 967\t Weight: [1.99287005]\t Bias: [0.0513117]\t Cost: 0.0002645575704008239\n",
            "Iteration: 968\t Weight: [1.99289817]\t Bias: [0.05110937]\t Cost: 0.0002624753101821434\n",
            "Iteration: 969\t Weight: [1.99292617]\t Bias: [0.05090784]\t Cost: 0.0002604094388636585\n",
            "Iteration: 970\t Weight: [1.99295406]\t Bias: [0.0507071]\t Cost: 0.000258359827452821\n",
            "Iteration: 971\t Weight: [1.99298185]\t Bias: [0.05050716]\t Cost: 0.0002563263479723589\n",
            "Iteration: 972\t Weight: [1.99300952]\t Bias: [0.050308]\t Cost: 0.0002543088734522619\n",
            "Iteration: 973\t Weight: [1.99303709]\t Bias: [0.05010963]\t Cost: 0.0002523072779218561\n",
            "Iteration: 974\t Weight: [1.99306454]\t Bias: [0.04991204]\t Cost: 0.0002503214364019821\n",
            "Iteration: 975\t Weight: [1.99309189]\t Bias: [0.04971523]\t Cost: 0.0002483512248971064\n",
            "Iteration: 976\t Weight: [1.99311913]\t Bias: [0.0495192]\t Cost: 0.00024639652038768923\n",
            "Iteration: 977\t Weight: [1.99314626]\t Bias: [0.04932394]\t Cost: 0.0002444572008223948\n",
            "Iteration: 978\t Weight: [1.99317329]\t Bias: [0.04912944]\t Cost: 0.00024253314511053304\n",
            "Iteration: 979\t Weight: [1.9932002]\t Bias: [0.04893572]\t Cost: 0.00024062423311451805\n",
            "Iteration: 980\t Weight: [1.99322702]\t Bias: [0.04874276]\t Cost: 0.0002387303456422927\n",
            "Iteration: 981\t Weight: [1.99325372]\t Bias: [0.04855056]\t Cost: 0.00023685136443993122\n",
            "Iteration: 982\t Weight: [1.99328033]\t Bias: [0.04835912]\t Cost: 0.00023498717218428704\n",
            "Iteration: 983\t Weight: [1.99330682]\t Bias: [0.04816843]\t Cost: 0.00023313765247559435\n",
            "Iteration: 984\t Weight: [1.99333321]\t Bias: [0.0479785]\t Cost: 0.00023130268983025668\n",
            "Iteration: 985\t Weight: [1.9933595]\t Bias: [0.04778931]\t Cost: 0.00022948216967359962\n",
            "Iteration: 986\t Weight: [1.99338569]\t Bias: [0.04760087]\t Cost: 0.00022767597833277638\n",
            "Iteration: 987\t Weight: [1.99341177]\t Bias: [0.04741318]\t Cost: 0.00022588400302958096\n",
            "Iteration: 988\t Weight: [1.99343775]\t Bias: [0.04722622]\t Cost: 0.00022410613187347198\n",
            "Iteration: 989\t Weight: [1.99346362]\t Bias: [0.04704]\t Cost: 0.00022234225385456554\n",
            "Iteration: 990\t Weight: [1.9934894]\t Bias: [0.04685451]\t Cost: 0.00022059225883673124\n",
            "Iteration: 991\t Weight: [1.99351507]\t Bias: [0.04666976]\t Cost: 0.00021885603755064382\n",
            "Iteration: 992\t Weight: [1.99354064]\t Bias: [0.04648574]\t Cost: 0.00021713348158703742\n",
            "Iteration: 993\t Weight: [1.99356611]\t Bias: [0.04630244]\t Cost: 0.0002154244833899001\n",
            "Iteration: 994\t Weight: [1.99359148]\t Bias: [0.04611986]\t Cost: 0.00021372893624977584\n",
            "Iteration: 995\t Weight: [1.99361675]\t Bias: [0.045938]\t Cost: 0.00021204673429706407\n",
            "Iteration: 996\t Weight: [1.99364192]\t Bias: [0.04575686]\t Cost: 0.00021037777249543888\n",
            "Iteration: 997\t Weight: [1.99366699]\t Bias: [0.04557644]\t Cost: 0.0002087219466353057\n",
            "Iteration: 998\t Weight: [1.99369196]\t Bias: [0.04539672]\t Cost: 0.0002070791533272729\n",
            "Iteration: 999\t Weight: [1.99371683]\t Bias: [0.04521772]\t Cost: 0.0002054492899956859\n",
            "Weight: [1.99371683] Bias: [0.04521772]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6VkaIc6KE2Q",
        "outputId": "e1ef2473-5e76-46f1-d9d2-1bdbff710bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "w = regressor.weight\n",
        "b = regressor.bias\n",
        "x=[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8] \n",
        "y=[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]\n",
        "plt.scatter(x,y)\n",
        "axes = plt.gca()\n",
        "x_vals = np.array(axes.get_xlim())\n",
        "y_vals = b + w * x_vals\n",
        "plt.plot(x_vals, y_vals)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}