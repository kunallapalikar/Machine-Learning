{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunallapalikar/Machine-Learning/blob/main/Kunal_Lapalikar(CT_28)_CT_CO_III_Year_Convolutional_Neural_Networks_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDWb8jzkqI3"
      },
      "source": [
        "# Part 1: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAxVZg8kqI6"
      },
      "source": [
        "###  Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4CSTapDRkqI9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3otQrU4JWLej"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKUqkgGkqJI"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtwFbXyskqJL",
        "outputId": "5fa6435e-4a50-4ea0-ff25-6693c715288b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test =to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A1KfUskqJT"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMtSvqMdkqJV",
        "outputId": "438d1715-d2e7-4224-de32-de54ce4cf2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               40100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,054\n",
            "Trainable params: 46,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aab-hxdkqJc"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MWvDXQgkqJf",
        "outputId": "0d4771cf-4353-4a93-f98d-2caedc660ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 14s 4ms/step - loss: 0.3699 - accuracy: 0.8846 - val_loss: 0.0759 - val_accuracy: 0.9764\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1480 - accuracy: 0.9550 - val_loss: 0.0513 - val_accuracy: 0.9837\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1159 - accuracy: 0.9656 - val_loss: 0.0472 - val_accuracy: 0.9857\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1008 - accuracy: 0.9694 - val_loss: 0.0362 - val_accuracy: 0.9884\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0930 - accuracy: 0.9720 - val_loss: 0.0337 - val_accuracy: 0.9883\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0884 - accuracy: 0.9736 - val_loss: 0.0317 - val_accuracy: 0.9890\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0777 - accuracy: 0.9767 - val_loss: 0.0328 - val_accuracy: 0.9902\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 0.0304 - val_accuracy: 0.9901\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0690 - accuracy: 0.9779 - val_loss: 0.0282 - val_accuracy: 0.9907\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0679 - accuracy: 0.9797 - val_loss: 0.0281 - val_accuracy: 0.9907\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0632 - accuracy: 0.9807 - val_loss: 0.0283 - val_accuracy: 0.9907\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0643 - accuracy: 0.9803 - val_loss: 0.0256 - val_accuracy: 0.9920\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.0233 - val_accuracy: 0.9919\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.0274 - val_accuracy: 0.9918\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0556 - accuracy: 0.9830 - val_loss: 0.0270 - val_accuracy: 0.9912\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0549 - accuracy: 0.9830 - val_loss: 0.0249 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0540 - accuracy: 0.9834 - val_loss: 0.0261 - val_accuracy: 0.9910\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0507 - accuracy: 0.9834 - val_loss: 0.0225 - val_accuracy: 0.9925\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0499 - accuracy: 0.9849 - val_loss: 0.0231 - val_accuracy: 0.9932\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.0238 - val_accuracy: 0.9921\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0503 - accuracy: 0.9846 - val_loss: 0.0226 - val_accuracy: 0.9918\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0247 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.0222 - val_accuracy: 0.9925\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.0221 - val_accuracy: 0.9937\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.0232 - val_accuracy: 0.9926\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.0247 - val_accuracy: 0.9930\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0232 - val_accuracy: 0.9925\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.0245 - val_accuracy: 0.9925\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.0236 - val_accuracy: 0.9926\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.0243 - val_accuracy: 0.9929\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0230 - val_accuracy: 0.9933\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 0.0234 - val_accuracy: 0.9930\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0238 - val_accuracy: 0.9928\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.0243 - val_accuracy: 0.9920\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.0219 - val_accuracy: 0.9935\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0210 - val_accuracy: 0.9936\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.0222 - val_accuracy: 0.9935\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0395 - accuracy: 0.9875 - val_loss: 0.0208 - val_accuracy: 0.9938\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 0.0230 - val_accuracy: 0.9931\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.0221 - val_accuracy: 0.9933\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0247 - val_accuracy: 0.9921\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.0269 - val_accuracy: 0.9922\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0256 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.0230 - val_accuracy: 0.9936\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0238 - val_accuracy: 0.9934\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.0250 - val_accuracy: 0.9925\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.0229 - val_accuracy: 0.9931\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.0215 - val_accuracy: 0.9938\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0349 - accuracy: 0.9886 - val_loss: 0.0280 - val_accuracy: 0.9917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b6bfdec10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprccy28kqJn"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74OuyWUkkqJq",
        "outputId": "a6bc4f65-f5e4-46d8-8692-b220fddc1427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.02798590436577797\n",
            "Test accuracy: 0.9916999936103821\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMO1hxHkqJw"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IHv0D_xhkqJx",
        "outputId": "4d82196b-b7b9-469c-f955-8c2ee999aa8f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.imshow(x_test[122].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFYYp7JEaHoj",
        "outputId": "fc0bdf42-513d-4aac-a0e3-9d493af838e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "li=[0.5, 0,0.4, 0,0,0]\n",
        "li=np.array(li)\n",
        "thresholded = (li>=0.5)*1\n",
        "thresholded "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ffffzwBkqJ3",
        "scrolled": true,
        "outputId": "6cf20612-7fb1-44fe-e2eb-73c6852b2432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Score:\n",
            " [7.5301581e-13 2.2734362e-08 1.6485122e-09 1.5422215e-07 1.0799337e-09\n",
            " 3.3590081e-10 6.7732480e-19 9.9999988e-01 1.0376655e-12 3.3686803e-08]\n",
            "\n",
            "Thresholded Score:\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            "\n",
            "Predicted Digit:\n",
            " [7]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "prediction = model.predict(x_test[122:123])\n",
        "print('Prediction Score:\\n',prediction[0])\n",
        "thresholded = (prediction>0.5)*1\n",
        "print('\\nThresholded Score:\\n',thresholded[0])\n",
        "print('\\nPredicted Digit:\\n',np.where(thresholded == 1)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKT5OJSVkqJ8"
      },
      "source": [
        "# Part 2: Applications of Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzUY5QxykqJ_"
      },
      "source": [
        "###  MobileNet Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPVmwIZkqKA",
        "outputId": "d5b5dc6a-d8f7-4e9e-9140-71ba1e7824fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenet_0.25_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 112, 112, 8)       216       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 112, 112, 8)      32        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 112, 112, 8)       0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 8)      72        \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 8)      32        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 112, 112, 8)       0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 112, 112, 16)      128       \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 16)     64        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 16)      0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 16)       144       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 16)       64        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 56, 56, 16)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 56, 56, 32)        512       \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 56, 56, 32)        1024      \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 28, 28, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 28, 28, 64)        4096      \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 14, 14, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 128)      0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 128)        1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 7, 7, 128)        512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 7, 7, 256)         32768     \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 256)        2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 7, 7, 256)         65536     \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1, 1, 256)        0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " conv_preds (Conv2D)         (None, 1, 1, 1000)        257000    \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 1000)              0         \n",
            "                                                                 \n",
            " predictions (Activation)    (None, 1000)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 475,544\n",
            "Trainable params: 470,072\n",
            "Non-trainable params: 5,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = MobileNet(input_shape=None, alpha=0.25, depth_multiplier=1, dropout=1e-3, \n",
        "                                 include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGjhRRmkqKI"
      },
      "source": [
        "###  Classify images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "qTFWBD9FkqKK",
        "outputId": "86a212f9-e1d2-46c7-bfe4-e1989550c272"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ee958b9391a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'download.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'download.png'"
          ]
        }
      ],
      "source": [
        "# Write the image name below\n",
        "\n",
        "img_path = 'download.png'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:\\n', decode_predictions(preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvQWG_8kqKQ"
      },
      "source": [
        "###  Extract CNN features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "3rT0iPnxkqKS",
        "outputId": "41cf1d4d-ef4f-40e7-84aa-d1edfebe36bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d9dc5588616d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFeature Shape:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFeatures:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "features = model.predict(x)\n",
        "print('\\nFeature Shape:\\n',features.shape)\n",
        "print('\\nFeatures:\\n',features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYHHR_bskqKY"
      },
      "source": [
        "###  Extract features from an arbitrary intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "uOrIUA2DkqKb",
        "outputId": "663824fe-a61c-49e3-a729-64ddea39a060"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-394c08beca9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv_dw_2_relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_dw_2_relu_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_minimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Features of conv_dw_2_relu:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_dw_2_relu_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1172\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'input')"
          ]
        }
      ],
      "source": [
        "model_minimal = Model(input=model.input, output=model.get_layer('conv_dw_2_relu').output)\n",
        "\n",
        "conv_dw_2_relu_features = model_minimal.predict(x)\n",
        "print('Features of conv_dw_2_relu:',conv_dw_2_relu_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPYajJZkqKh"
      },
      "source": [
        "### You can extract these features and use the base network as a feature extractor for your problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5z5cFn5kqKj"
      },
      "source": [
        "# Part 3: Deep Convolution Layer Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Yjr6DcimkqKm",
        "outputId": "076d1b7c-92a6-4d2e-a162-05b9db145058"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-03f63042c631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import matplotlib as mp\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOMgk22xkqKr"
      },
      "source": [
        "### Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6PBNav6kqKt"
      },
      "outputs": [],
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-nifFGhkqKy"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9LkN_paDkqKz"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784],name=\"x-in\")\n",
        "true_y = tf.placeholder(tf.float32, [None, 10],name=\"y-in\")\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "hidden_1 = slim.conv2d(x_image,5,[5,5])\n",
        "pool_1 = slim.max_pool2d(hidden_1,[2,2])\n",
        "hidden_2 = slim.conv2d(pool_1,5,[5,5])\n",
        "pool_2 = slim.max_pool2d(hidden_2,[2,2])\n",
        "hidden_3 = slim.conv2d(pool_2,20,[5,5])\n",
        "hidden_3 = slim.dropout(hidden_3,keep_prob)\n",
        "out_y = slim.fully_connected(slim.flatten(hidden_3),10,activation_fn=tf.nn.softmax)\n",
        "\n",
        "cross_entropy = -tf.reduce_sum(true_y*tf.log(out_y))\n",
        "correct_prediction = tf.equal(tf.argmax(out_y,1), tf.argmax(true_y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEodGsOUkqK5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UPBduFekqK6"
      },
      "outputs": [],
      "source": [
        "batchSize = 50\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "for i in range(1001):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    sess.run(train_step, feed_dict={x:batch[0],true_y:batch[1], keep_prob:0.5})\n",
        "    if i % 100 == 0 and i != 0:\n",
        "        trainAccuracy = sess.run(accuracy, feed_dict={x:batch[0],true_y:batch[1], keep_prob:1.0})\n",
        "        print(\"step %d, training accuracy %g\"%(i, trainAccuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTeqbaJkqLA"
      },
      "source": [
        "### Testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-JBoLBAkqLB"
      },
      "outputs": [],
      "source": [
        "testAccuracy = sess.run(accuracy, feed_dict={x:mnist.test.images,true_y:mnist.test.labels, keep_prob:1.0})\n",
        "print(\"test accuracy %g\"%(testAccuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2BhkZBskqLI"
      },
      "source": [
        "### Get activation values and plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8DOheo-hkqLJ"
      },
      "outputs": [],
      "source": [
        "def getActivations(layer,stimuli):\n",
        "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
        "    plotNNFilter(units)\n",
        "    \n",
        "def plotNNFilter(units):\n",
        "    filters = units.shape[3]\n",
        "    plt.figure(1, figsize=(20,20))\n",
        "    n_columns = 6\n",
        "    n_rows = math.ceil(filters / n_columns) + 1\n",
        "    for i in range(filters):\n",
        "        plt.subplot(n_rows, n_columns, i+1)\n",
        "        plt.title('Filter ' + str(i))\n",
        "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkoaARCnkqLO"
      },
      "source": [
        "### Input Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUdOll7bkqLQ"
      },
      "outputs": [],
      "source": [
        "imageToUse = mnist.test.images[0]\n",
        "plt.imshow(np.reshape(imageToUse,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZ5UZDkkqLV"
      },
      "source": [
        "### Activation in Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5dxXfvPkqLX"
      },
      "outputs": [],
      "source": [
        "getActivations(hidden_1,imageToUse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9gNAvrkqLd"
      },
      "source": [
        "### Activation in Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlb3LGrWkqLe"
      },
      "outputs": [],
      "source": [
        "getActivations(hidden_2,imageToUse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqGvOEkkqLl"
      },
      "source": [
        "### Activation in Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmkgnW5ckqLo"
      },
      "outputs": [],
      "source": [
        "getActivations(hidden_3,imageToUse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awq5VogkqLt"
      },
      "source": [
        "# Part 4: Design Choices in Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGnsygzkqLv"
      },
      "source": [
        "## Influence of convolution size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVCTsJPkqLy"
      },
      "source": [
        "### Model with (3 x 3) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5wWkLbAkqL0"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAuW0NOHkqL7"
      },
      "source": [
        "### Model with (7 x 7) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnphlXbvkqL8"
      },
      "outputs": [],
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2WASoQkqMD"
      },
      "source": [
        "## Striding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h9XyTZKkqME"
      },
      "source": [
        "### Model with (7 x 7) Convolution with 2 Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K39I1weskqMF"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=2, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6_wR8GkqMK"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3kln95ykqMM"
      },
      "source": [
        "### Model with (7 x 7) Convolution with Same Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QinhffvkkqMO"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=1, padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLPfWDdYkqMT"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhAfYO0kqMV"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (2 x 2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMSL5flZkqMW"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HsHtxt0kqMc"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (3 x 3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w9kCVL7kqMe"
      },
      "outputs": [],
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzV7LwepkqMn"
      },
      "source": [
        "### What are your findings?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Kunal Lapalikar(CT-28)_CT_CO_III_Year_Convolutional_Neural_Networks_checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}